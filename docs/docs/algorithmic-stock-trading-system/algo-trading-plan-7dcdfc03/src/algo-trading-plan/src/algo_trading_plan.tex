\documentclass[11pt,a4paper,twoside]{report}

% ============================================================================
% PACKAGES
% ============================================================================

% Page geometry and layout
\usepackage[margin=1in,inner=1.25in,outer=1in]{geometry}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{titletoc}

% Typography and fonts
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage{setspace}

% Colors and graphics
\usepackage[dvipsnames,svgnames,x11names]{xcolor}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric,arrows.meta,positioning,fit,backgrounds,calc,decorations.pathreplacing}

% Tables
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{array}
\usepackage{colortbl}

% Code listings
\usepackage{listings}
\usepackage{listingsutf8}

% Math
\usepackage{amsmath}
\usepackage{amssymb}

% Hyperlinks and references
\usepackage[colorlinks=true,linkcolor=NavyBlue,urlcolor=NavyBlue,citecolor=NavyBlue]{hyperref}
\usepackage{bookmark}

% Lists and formatting
\usepackage{enumitem}
\usepackage{parskip}

% Boxes and callouts
\usepackage[most]{tcolorbox}

% ============================================================================
% COLOR DEFINITIONS
% ============================================================================

\definecolor{primaryblue}{RGB}{0,82,147}
\definecolor{secondaryblue}{RGB}{0,120,174}
\definecolor{accentgreen}{RGB}{0,150,100}
\definecolor{warningorange}{RGB}{230,126,34}
\definecolor{lightgray}{RGB}{248,248,248}
\definecolor{codebg}{RGB}{250,250,250}
\definecolor{codeborder}{RGB}{220,220,220}
\definecolor{commentgreen}{RGB}{0,128,0}
\definecolor{keywordblue}{RGB}{0,0,180}
\definecolor{stringred}{RGB}{163,21,21}

% ============================================================================
% CODE LISTING CONFIGURATION
% ============================================================================

\lstdefinestyle{pythonstyle}{
    language=Python,
    backgroundcolor=\color{codebg},
    basicstyle=\ttfamily\small,
    keywordstyle=\color{keywordblue}\bfseries,
    commentstyle=\color{commentgreen}\itshape,
    stringstyle=\color{stringred},
    numberstyle=\tiny\color{gray},
    numbers=left,
    numbersep=8pt,
    breaklines=true,
    breakatwhitespace=true,
    tabsize=4,
    showstringspaces=false,
    frame=single,
    rulecolor=\color{codeborder},
    framesep=4pt,
    xleftmargin=16pt,
    framexleftmargin=16pt,
    aboveskip=12pt,
    belowskip=12pt,
    morekeywords={self,True,False,None,async,await,yield,lambda},
    literate={->}{$\rightarrow$}1,
}

\lstdefinestyle{sqlstyle}{
    language=SQL,
    backgroundcolor=\color{codebg},
    basicstyle=\ttfamily\small,
    keywordstyle=\color{keywordblue}\bfseries,
    commentstyle=\color{commentgreen}\itshape,
    stringstyle=\color{stringred},
    numberstyle=\tiny\color{gray},
    numbers=left,
    numbersep=8pt,
    breaklines=true,
    frame=single,
    rulecolor=\color{codeborder},
    framesep=4pt,
    xleftmargin=16pt,
    framexleftmargin=16pt,
    aboveskip=12pt,
    belowskip=12pt,
    morekeywords={TIMESTAMPTZ,SERIAL,JSONB,BIGINT,VARCHAR,DECIMAL,UUID,PRIMARY,KEY,NOT,NULL},
}

\lstdefinestyle{yamlstyle}{
    backgroundcolor=\color{codebg},
    basicstyle=\ttfamily\small,
    keywordstyle=\color{keywordblue},
    commentstyle=\color{commentgreen}\itshape,
    stringstyle=\color{stringred},
    numberstyle=\tiny\color{gray},
    numbers=left,
    numbersep=8pt,
    breaklines=true,
    frame=single,
    rulecolor=\color{codeborder},
    framesep=4pt,
    xleftmargin=16pt,
    framexleftmargin=16pt,
    aboveskip=12pt,
    belowskip=12pt,
}

\lstdefinestyle{bashstyle}{
    language=bash,
    backgroundcolor=\color{codebg},
    basicstyle=\ttfamily\small,
    keywordstyle=\color{keywordblue},
    commentstyle=\color{commentgreen}\itshape,
    stringstyle=\color{stringred},
    numberstyle=\tiny\color{gray},
    numbers=left,
    numbersep=8pt,
    breaklines=true,
    frame=single,
    rulecolor=\color{codeborder},
    framesep=4pt,
    xleftmargin=16pt,
    framexleftmargin=16pt,
    aboveskip=12pt,
    belowskip=12pt,
}

\lstset{style=pythonstyle}

% ============================================================================
% TCOLORBOX DEFINITIONS
% ============================================================================

\newtcolorbox{notebox}[1][]{
    colback=blue!5!white,
    colframe=primaryblue,
    fonttitle=\bfseries,
    title=Note,
    #1
}

\newtcolorbox{warningbox}[1][]{
    colback=orange!5!white,
    colframe=warningorange,
    fonttitle=\bfseries,
    title=Important,
    #1
}

\newtcolorbox{conceptbox}[2][]{
    colback=green!5!white,
    colframe=accentgreen,
    fonttitle=\bfseries,
    title=#2,
    #1
}

\newtcolorbox{codebox}[1][]{
    colback=codebg,
    colframe=codeborder,
    boxrule=0.5pt,
    left=2pt,
    right=2pt,
    top=2pt,
    bottom=2pt,
    #1
}

% ============================================================================
% HEADER AND FOOTER CONFIGURATION
% ============================================================================

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\thepage}
\fancyhead[RE]{\leftmark}
\fancyhead[LO]{\rightmark}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0pt}

\fancypagestyle{plain}{
    \fancyhf{}
    \fancyfoot[C]{\thepage}
    \renewcommand{\headrulewidth}{0pt}
}

% ============================================================================
% CHAPTER AND SECTION FORMATTING
% ============================================================================

\titleformat{\chapter}[display]
    {\normalfont\huge\bfseries\color{primaryblue}}
    {\chaptertitlename\ \thechapter}
    {20pt}
    {\Huge}

\titleformat{\section}
    {\normalfont\Large\bfseries\color{primaryblue}}
    {\thesection}
    {1em}
    {}

\titleformat{\subsection}
    {\normalfont\large\bfseries\color{secondaryblue}}
    {\thesubsection}
    {1em}
    {}

\titleformat{\subsubsection}
    {\normalfont\normalsize\bfseries\color{secondaryblue}}
    {\thesubsubsection}
    {1em}
    {}

% ============================================================================
% CUSTOM COMMANDS
% ============================================================================

\newcommand{\code}[1]{\texttt{\small #1}}
\newcommand{\term}[1]{\textit{#1}}
\newcommand{\highlight}[1]{\colorbox{yellow!30}{#1}}

% ============================================================================
% DOCUMENT INFORMATION
% ============================================================================

\title{
    \vspace{-2cm}
    \begin{tikzpicture}[remember picture,overlay]
        \fill[primaryblue] (-5,-3) rectangle (20,3);
    \end{tikzpicture}
    \vspace{1cm}
    {\color{white}\Huge\bfseries Algorithmic Stock Trading System}\\[0.5cm]
    {\color{white}\Large Comprehensive Development Plan}\\[0.3cm]
    {\color{white}\large Architecture, Implementation, and Deployment Guide}
}
\author{
    \Large Technical Specification Document\\[0.3cm]
    \normalsize Version 1.0
}
\date{\today}

% ============================================================================
% DOCUMENT START
% ============================================================================

\begin{document}

% Title Page
\begin{titlepage}
    \centering
    \vspace*{1cm}
    
    \begin{tikzpicture}[remember picture,overlay]
        \fill[primaryblue] (current page.north west) rectangle ([yshift=-8cm]current page.north east);
    \end{tikzpicture}
    
    \vspace{1cm}
    {\color{white}\Huge\bfseries Algorithmic Stock Trading System}\\[0.8cm]
    {\color{white}\LARGE Comprehensive Development Plan}\\[0.5cm]
    {\color{white}\large Architecture, Implementation, and Deployment Guide}
    
    \vspace{4cm}
    
    \begin{tikzpicture}[scale=0.8]
        % Trading system icon
        \draw[primaryblue, line width=2pt] (0,0) -- (2,1) -- (3,0.5) -- (4.5,2) -- (6,1.5) -- (7.5,2.5);
        \draw[accentgreen, line width=1.5pt, dashed] (0,1) -- (7.5,1);
        \foreach \x in {0,2,3,4.5,6,7.5} {
            \fill[primaryblue] (\x,{0.5+rand*0.5+1}) circle (4pt);
        }
        \draw[warningorange, line width=1pt] (0,-0.5) rectangle (7.5,3);
        \node[primaryblue] at (3.75,-1) {\large\bfseries Market Analysis Engine};
    \end{tikzpicture}
    
    \vspace{3cm}
    
    \begin{tabular}{ll}
        \textbf{Document Type:} & Technical Specification \\
        \textbf{Version:} & 1.0 \\
        \textbf{Date:} & \today \\
        \textbf{Status:} & Draft \\
    \end{tabular}
    
    \vfill
    
    {\small\itshape This document synthesizes knowledge from foundational texts in value investing, technical analysis, trading psychology, quantitative methods, and machine learning for algorithmic trading.}
    
\end{titlepage}

% Table of Contents
\tableofcontents
\newpage

% List of Figures
\listoffigures
\addcontentsline{toc}{chapter}{List of Figures}

% List of Tables
\listoftables
\addcontentsline{toc}{chapter}{List of Tables}

% List of Listings
\lstlistoflistings
\addcontentsline{toc}{chapter}{List of Code Listings}
\newpage

% ============================================================================
% CHAPTER 1: EXECUTIVE SUMMARY
% ============================================================================

\chapter{Executive Summary}
\label{ch:executive-summary}

\section{Document Purpose}

This document presents a comprehensive development plan for building a professional-grade algorithmic stock trading system. The plan integrates theoretical foundations from established financial literature with modern software engineering practices to create a robust, scalable, and maintainable trading platform.

\section{Knowledge Foundations}

The system design draws from multiple domains of expertise, each contributing essential components to the overall architecture:

\begin{table}[htbp]
    \centering
    \caption{Core Knowledge Domains and Source References}
    \label{tab:knowledge-domains}
    \begin{tabularx}{\textwidth}{@{}l X l@{}}
        \toprule
        \textbf{Domain} & \textbf{Key Concepts} & \textbf{Primary Sources} \\
        \midrule
        Fundamental Analysis & Value investing, company financials, long-term strategy & Graham \\
        Technical Analysis & Chart patterns, indicators, price/volume analysis & Murphy, O'Neil, Pring \\
        Trading Psychology & Discipline, risk tolerance, emotional control & Douglas, Schwager \\
        Quantitative Methods & Backtesting, statistical modeling, systematic strategies & Chan (both books) \\
        Machine Learning & Predictive models, feature engineering & Jansen, López de Prado \\
        System Architecture & Direct market access, execution algorithms & Johnson, Aldridge \\
        \bottomrule
    \end{tabularx}
\end{table}

\section{System Overview}

The proposed algorithmic trading system consists of several interconnected components designed to work in concert:

\begin{enumerate}[label=\arabic*.]
    \item \textbf{Data Layer}: Real-time and historical market data ingestion with comprehensive feature engineering
    \item \textbf{Strategy Engine}: Multiple strategy implementations spanning fundamental, technical, and quantitative approaches
    \item \textbf{Backtesting Framework}: Event-driven simulation with walk-forward optimization
    \item \textbf{Risk Management}: Position sizing, portfolio constraints, and automated risk controls
    \item \textbf{Machine Learning Pipeline}: Predictive modeling with proper cross-validation techniques
    \item \textbf{Execution Engine}: Broker integration with smart order routing
    \item \textbf{Monitoring Dashboard}: Real-time analytics and alerting
\end{enumerate}

\section{Success Criteria}

The system must meet the following quantitative benchmarks to be considered production-ready:

\begin{itemize}
    \item Sharpe Ratio $> 1.0$ on out-of-sample data
    \item Profit Factor $> 1.5$
    \item Maximum Drawdown $< 15\%$
    \item Daily Value at Risk (VaR) $< 2\%$
    \item Order Fill Rate $> 95\%$
    \item Execution Slippage $< 10$ basis points
\end{itemize}

% ============================================================================
% CHAPTER 2: SYSTEM REQUIREMENTS
% ============================================================================

\chapter{System Requirements Specification}
\label{ch:requirements}

\section{Functional Requirements}

\subsection{Data Management}

\begin{table}[htbp]
    \centering
    \caption{Data Management Requirements}
    \label{tab:data-requirements}
    \begin{tabularx}{\textwidth}{@{}l l X@{}}
        \toprule
        \textbf{ID} & \textbf{Priority} & \textbf{Requirement Description} \\
        \midrule
        FR-D01 & Critical & System shall ingest real-time market data with latency $< 100$ms \\
        FR-D02 & Critical & System shall store historical OHLCV data for all tracked symbols \\
        FR-D03 & High & System shall retrieve fundamental data (earnings, ratios, filings) \\
        FR-D04 & Medium & System shall process alternative data (news, sentiment, SEC filings) \\
        FR-D05 & High & System shall compute technical indicators in real-time \\
        FR-D06 & High & System shall handle data gaps and corporate actions appropriately \\
        \bottomrule
    \end{tabularx}
\end{table}

\subsection{Strategy Management}

\begin{table}[htbp]
    \centering
    \caption{Strategy Management Requirements}
    \label{tab:strategy-requirements}
    \begin{tabularx}{\textwidth}{@{}l l X@{}}
        \toprule
        \textbf{ID} & \textbf{Priority} & \textbf{Requirement Description} \\
        \midrule
        FR-S01 & Critical & System shall support multiple concurrent trading strategies \\
        FR-S02 & Critical & System shall generate buy/sell/hold signals with confidence scores \\
        FR-S03 & High & System shall support strategy parameter optimization \\
        FR-S04 & High & System shall enable/disable strategies without system restart \\
        FR-S05 & Medium & System shall support strategy combination and ensemble methods \\
        \bottomrule
    \end{tabularx}
\end{table}

\subsection{Execution and Order Management}

\begin{table}[htbp]
    \centering
    \caption{Execution Requirements}
    \label{tab:execution-requirements}
    \begin{tabularx}{\textwidth}{@{}l l X@{}}
        \toprule
        \textbf{ID} & \textbf{Priority} & \textbf{Requirement Description} \\
        \midrule
        FR-E01 & Critical & System shall submit orders via broker API \\
        FR-E02 & Critical & System shall track order status throughout lifecycle \\
        FR-E03 & Critical & System shall support market, limit, and stop orders \\
        FR-E04 & High & System shall implement execution algorithms (TWAP, VWAP) \\
        FR-E05 & High & System shall provide paper trading mode for validation \\
        FR-E06 & High & System shall handle partial fills and order modifications \\
        \bottomrule
    \end{tabularx}
\end{table}

\section{Non-Functional Requirements}

\subsection{Performance Requirements}

\begin{conceptbox}{Performance Targets}
The system is designed for standard algorithmic trading, not high-frequency trading (HFT). Target latencies are measured in hundreds of milliseconds rather than microseconds.
\end{conceptbox}

\begin{table}[htbp]
    \centering
    \caption{Performance Requirements}
    \label{tab:performance-requirements}
    \begin{tabularx}{\textwidth}{@{}l l X@{}}
        \toprule
        \textbf{ID} & \textbf{Metric} & \textbf{Target Value} \\
        \midrule
        NFR-P01 & Signal Generation Latency & $< 500$ms from data receipt to signal \\
        NFR-P02 & Order Submission Latency & $< 200$ms from signal to order sent \\
        NFR-P03 & Concurrent Symbols & $\geq 1000$ symbols monitored simultaneously \\
        NFR-P04 & Historical Data Processing & $\geq 10$ years of data processed in $< 1$ hour \\
        NFR-P05 & System Uptime & $\geq 99.9\%$ during market hours \\
        \bottomrule
    \end{tabularx}
\end{table}

\subsection{Security Requirements}

\begin{itemize}
    \item \textbf{NFR-S01}: All API credentials shall be encrypted at rest using AES-256
    \item \textbf{NFR-S02}: Network communications shall use TLS 1.3 or higher
    \item \textbf{NFR-S03}: System shall implement role-based access control
    \item \textbf{NFR-S04}: All trading actions shall be logged with non-repudiation guarantees
    \item \textbf{NFR-S05}: System shall support multi-factor authentication for administrative access
\end{itemize}

\subsection{Auditability Requirements}

\begin{itemize}
    \item \textbf{NFR-A01}: All signals generated shall be logged with timestamps and rationale
    \item \textbf{NFR-A02}: All orders shall be tracked from creation through settlement
    \item \textbf{NFR-A03}: Portfolio state shall be snapshotted at configurable intervals
    \item \textbf{NFR-A04}: System shall generate regulatory-compliant trade reports
\end{itemize}

% ============================================================================
% CHAPTER 3: SYSTEM ARCHITECTURE
% ============================================================================

\chapter{System Architecture}
\label{ch:architecture}

\section{High-Level Architecture Overview}

The system follows a modular, event-driven architecture that separates concerns across distinct components. This design enables independent scaling, testing, and deployment of each module.

\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[
        node distance=1.5cm,
        box/.style={rectangle, draw=primaryblue, fill=blue!5, thick, minimum width=3cm, minimum height=1cm, align=center, rounded corners=3pt},
        smallbox/.style={rectangle, draw=secondaryblue, fill=blue!3, thick, minimum width=2.5cm, minimum height=0.8cm, align=center, rounded corners=2pt, font=\small},
        bus/.style={rectangle, draw=accentgreen, fill=green!10, thick, minimum width=14cm, minimum height=0.8cm, align=center},
        persistence/.style={rectangle, draw=warningorange, fill=orange!10, thick, minimum width=14cm, minimum height=0.8cm, align=center},
        arrow/.style={-Stealth, thick, primaryblue}
    ]
        
        % Title
        \node[font=\Large\bfseries, primaryblue] at (0,5.5) {Algorithmic Trading System Architecture};
        
        % Top layer boxes
        \node[box] (data) at (-5,4) {Data Layer};
        \node[box] (strategy) at (-1.5,4) {Strategy\\Engine};
        \node[box] (execution) at (2,4) {Execution\\Engine};
        \node[box] (analytics) at (5.5,4) {Analytics \&\\Monitoring};
        
        % Message bus
        \node[bus] (bus) at (0,2) {Message Bus / Event Queue (Redis Streams)};
        
        % Bottom layer boxes
        \node[smallbox] (risk) at (-5,0) {Risk\\Manager};
        \node[smallbox] (backtest) at (-1.5,0) {Backtesting\\Engine};
        \node[smallbox] (portfolio) at (2,0) {Portfolio\\Manager};
        \node[smallbox] (ml) at (5.5,0) {ML\\Pipeline};
        
        % Persistence layer
        \node[persistence] (db) at (0,-2) {Persistence Layer (TimescaleDB + Redis Cache)};
        
        % Arrows from top to bus
        \draw[arrow] (data) -- (data |- bus.north);
        \draw[arrow] (strategy) -- (strategy |- bus.north);
        \draw[arrow] (execution) -- (execution |- bus.north);
        \draw[arrow] (analytics) -- (analytics |- bus.north);
        
        % Arrows from bus to bottom
        \draw[arrow] (risk |- bus.south) -- (risk);
        \draw[arrow] (backtest |- bus.south) -- (backtest);
        \draw[arrow] (portfolio |- bus.south) -- (portfolio);
        \draw[arrow] (ml |- bus.south) -- (ml);
        
        % Arrows to persistence
        \draw[arrow] (risk) -- (risk |- db.north);
        \draw[arrow] (backtest) -- (backtest |- db.north);
        \draw[arrow] (portfolio) -- (portfolio |- db.north);
        \draw[arrow] (ml) -- (ml |- db.north);
        
    \end{tikzpicture}
    \caption{High-Level System Architecture Diagram}
    \label{fig:system-architecture}
\end{figure}

\section{Component Specifications}

\subsection{Data Layer}

The Data Layer is responsible for all data acquisition, normalization, and feature engineering operations.

\begin{table}[htbp]
    \centering
    \caption{Data Layer Component Structure}
    \label{tab:data-layer-structure}
    \begin{tabularx}{\textwidth}{@{}l l X@{}}
        \toprule
        \textbf{Sub-Module} & \textbf{File} & \textbf{Responsibility} \\
        \midrule
        \multirow{4}{*}{Connectors} 
            & \code{market\_data\_feed.py} & Real-time streaming price feeds \\
            & \code{historical\_data.py} & Historical OHLCV data retrieval \\
            & \code{fundamental\_data.py} & Financial statements, ratios, earnings \\
            & \code{alternative\_data.py} & News, sentiment, SEC filings \\
        \midrule
        \multirow{3}{*}{Processors}
            & \code{data\_cleaner.py} & Handle missing data, outliers, gaps \\
            & \code{normalizer.py} & Standardize formats across sources \\
            & \code{feature\_engineer.py} & Technical indicators, derived features \\
        \midrule
        \multirow{2}{*}{Storage}
            & \code{time\_series\_db.py} & TimescaleDB interface \\
            & \code{cache\_manager.py} & Redis caching for hot data \\
        \bottomrule
    \end{tabularx}
\end{table}

\subsection{Strategy Engine}

The Strategy Engine implements the trading logic, signal generation, and position sizing algorithms.

\begin{table}[htbp]
    \centering
    \caption{Strategy Engine Component Structure}
    \label{tab:strategy-engine-structure}
    \begin{tabularx}{\textwidth}{@{}l l X@{}}
        \toprule
        \textbf{Category} & \textbf{File} & \textbf{Description} \\
        \midrule
        \multirow{3}{*}{Base}
            & \code{strategy\_interface.py} & Abstract base class for strategies \\
            & \code{signal.py} & Signal data structures \\
            & \code{position.py} & Position sizing logic \\
        \midrule
        \multirow{5}{*}{Technical}
            & \code{moving\_average.py} & MA crossover strategies \\
            & \code{momentum.py} & RSI, MACD-based strategies \\
            & \code{mean\_reversion.py} & Bollinger Bands, statistical arbitrage \\
            & \code{canslim.py} & O'Neil's CAN SLIM implementation \\
            & \code{pattern\_recognition.py} & Chart pattern detection \\
        \midrule
        \multirow{3}{*}{Fundamental}
            & \code{value\_investing.py} & Graham-style value metrics \\
            & \code{growth\_investing.py} & PEG ratio, revenue growth \\
            & \code{quality\_screen.py} & ROE, debt ratios, margins \\
        \midrule
        \multirow{3}{*}{Quantitative}
            & \code{statistical\_arb.py} & Pairs trading, cointegration \\
            & \code{factor\_models.py} & Fama-French factor implementation \\
            & \code{regime\_detection.py} & Market regime classification \\
        \midrule
        \multirow{4}{*}{ML-Based}
            & \code{lstm\_predictor.py} & Price direction prediction \\
            & \code{random\_forest\_signal.py} & Classification-based signals \\
            & \code{reinforcement\_agent.py} & RL-based trading agent \\
            & \code{ensemble\_strategy.py} & Multi-model combination \\
        \bottomrule
    \end{tabularx}
\end{table}

\subsection{Execution Engine}

The Execution Engine manages all aspects of order lifecycle from creation through settlement.

\begin{table}[htbp]
    \centering
    \caption{Execution Engine Component Structure}
    \label{tab:execution-engine-structure}
    \begin{tabularx}{\textwidth}{@{}l l X@{}}
        \toprule
        \textbf{Sub-Module} & \textbf{File} & \textbf{Responsibility} \\
        \midrule
        \multirow{3}{*}{Order Management}
            & \code{order.py} & Order objects (market, limit, stop) \\
            & \code{order\_router.py} & Route orders to appropriate broker \\
            & \code{order\_tracker.py} & Track order status through lifecycle \\
        \midrule
        \multirow{4}{*}{Brokers}
            & \code{broker\_interface.py} & Abstract broker API \\
            & \code{alpaca\_broker.py} & Alpaca Markets integration \\
            & \code{interactive\_brokers.py} & IBKR TWS integration \\
            & \code{paper\_trading.py} & Simulated execution for testing \\
        \midrule
        \multirow{3}{*}{Algorithms}
            & \code{twap.py} & Time-weighted average price execution \\
            & \code{vwap.py} & Volume-weighted average price execution \\
            & \code{iceberg.py} & Iceberg order execution \\
        \midrule
        \multirow{2}{*}{Cost Models}
            & \code{slippage\_model.py} & Estimate execution costs \\
            & \code{market\_impact.py} & Model market impact of large orders \\
        \bottomrule
    \end{tabularx}
\end{table}

\section{Data Flow Architecture}

\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[
        node distance=1.2cm and 2cm,
        process/.style={rectangle, draw=primaryblue, fill=blue!10, thick, minimum width=2.8cm, minimum height=0.9cm, align=center, rounded corners=3pt, font=\small},
        data/.style={cylinder, draw=accentgreen, fill=green!10, thick, minimum width=1.8cm, minimum height=1cm, align=center, shape border rotate=90, font=\small},
        decision/.style={diamond, draw=warningorange, fill=orange!10, thick, minimum width=1.5cm, minimum height=1cm, align=center, aspect=2, font=\small},
        arrow/.style={-Stealth, thick}
    ]
        
        % Data sources
        \node[data] (source) {Market\\Data};
        \node[process, right=of source] (ingest) {Data\\Ingestion};
        \node[process, right=of ingest] (features) {Feature\\Engineering};
        \node[process, right=of features] (strategy) {Signal\\Generation};
        \node[decision, below=of strategy] (risk) {Risk\\Check};
        \node[process, left=of risk] (sizing) {Position\\Sizing};
        \node[process, below=of risk] (execution) {Order\\Execution};
        \node[data, right=of execution] (portfolio) {Portfolio\\State};
        \node[process, below=of execution] (analytics) {Performance\\Analytics};
        
        % Arrows
        \draw[arrow] (source) -- (ingest);
        \draw[arrow] (ingest) -- (features);
        \draw[arrow] (features) -- (strategy);
        \draw[arrow] (strategy) -- (risk);
        \draw[arrow] (sizing) -- (risk);
        \draw[arrow] (risk) -- node[right, font=\scriptsize] {Pass} (execution);
        \draw[arrow] (execution) -- (portfolio);
        \draw[arrow] (portfolio) |- (analytics);
        \draw[arrow, dashed] (analytics) -| node[below, font=\scriptsize] {Feedback} (strategy);
        
        % Reject path
        \draw[arrow, red, dashed] (risk.west) -- ++(-0.5,0) |- node[left, font=\scriptsize, pos=0.25] {Reject} (analytics);
        
    \end{tikzpicture}
    \caption{Data Flow Through the Trading System}
    \label{fig:data-flow}
\end{figure}

\section{Database Schema Design}

The persistence layer uses TimescaleDB, a PostgreSQL extension optimized for time-series data.

\begin{lstlisting}[style=sqlstyle, caption={Core Database Schema}, label={lst:db-schema}]
-- Core price data (TimescaleDB hypertable)
CREATE TABLE ohlcv (
    symbol          VARCHAR(10) NOT NULL,
    timestamp       TIMESTAMPTZ NOT NULL,
    open            DECIMAL(12,4),
    high            DECIMAL(12,4),
    low             DECIMAL(12,4),
    close           DECIMAL(12,4),
    volume          BIGINT,
    adjusted_close  DECIMAL(12,4),
    PRIMARY KEY (symbol, timestamp)
);
SELECT create_hypertable('ohlcv', 'timestamp');

-- Trading signals generated by strategies
CREATE TABLE signals (
    id              SERIAL PRIMARY KEY,
    strategy_id     VARCHAR(50) NOT NULL,
    symbol          VARCHAR(10) NOT NULL,
    timestamp       TIMESTAMPTZ NOT NULL,
    signal_type     VARCHAR(10),  -- BUY, SELL, HOLD
    strength        DECIMAL(5,4), -- 0.0 to 1.0
    metadata        JSONB
);
CREATE INDEX idx_signals_symbol_ts ON signals(symbol, timestamp);

-- Order and execution tracking
CREATE TABLE orders (
    id              UUID PRIMARY KEY,
    symbol          VARCHAR(10) NOT NULL,
    side            VARCHAR(4),   -- BUY, SELL
    order_type      VARCHAR(10),  -- MARKET, LIMIT, STOP
    quantity        INTEGER,
    limit_price     DECIMAL(12,4),
    status          VARCHAR(20),
    created_at      TIMESTAMPTZ,
    filled_at       TIMESTAMPTZ,
    filled_price    DECIMAL(12,4),
    commission      DECIMAL(10,4)
);
CREATE INDEX idx_orders_status ON orders(status, created_at);

-- Portfolio state snapshots
CREATE TABLE portfolio_snapshots (
    id              SERIAL PRIMARY KEY,
    timestamp       TIMESTAMPTZ NOT NULL,
    total_value     DECIMAL(15,2),
    cash            DECIMAL(15,2),
    positions       JSONB,
    daily_pnl       DECIMAL(12,2),
    cumulative_pnl  DECIMAL(15,2)
);
SELECT create_hypertable('portfolio_snapshots', 'timestamp');
\end{lstlisting}

% ============================================================================
% CHAPTER 4: DATA INFRASTRUCTURE
% ============================================================================

\chapter{Data Infrastructure}
\label{ch:data-infrastructure}

\section{Data Sources Integration}

Successful algorithmic trading requires diverse, high-quality data sources. The system integrates multiple providers to ensure comprehensive market coverage.

\begin{table}[htbp]
    \centering
    \caption{Data Source Specifications}
    \label{tab:data-sources}
    \begin{tabularx}{\textwidth}{@{}l l l X@{}}
        \toprule
        \textbf{Data Type} & \textbf{Source Options} & \textbf{Update Freq.} & \textbf{Purpose} \\
        \midrule
        Real-time Prices & Alpaca, Polygon.io, IEX Cloud & Streaming & Live trading signals \\
        Historical OHLCV & Yahoo Finance, Alpha Vantage & Daily & Backtesting \\
        Fundamentals & SEC EDGAR, Financial Modeling Prep & Quarterly & Value screening \\
        News/Sentiment & NewsAPI, Twitter API, Reddit & Real-time & Sentiment analysis \\
        Economic Data & FRED, World Bank & Monthly & Macro regime detection \\
        Options Data & CBOE, Polygon.io & Daily & Volatility analysis \\
        \bottomrule
    \end{tabularx}
\end{table}

\section{Feature Engineering Pipeline}

\subsection{Technical Indicators Implementation}

The feature engineering pipeline implements indicators from Murphy's \textit{Technical Analysis of the Financial Markets} and Pring's \textit{Technical Analysis Explained}.

\begin{lstlisting}[caption={Technical Indicators Implementation}, label={lst:technical-indicators}]
import pandas as pd
import numpy as np
from typing import Tuple

class TechnicalIndicators:
    """
    Implements technical indicators from 'Technical Analysis 
    of the Financial Markets' by John J. Murphy.
    """
    
    @staticmethod
    def sma(prices: pd.Series, period: int) -> pd.Series:
        """Simple Moving Average"""
        return prices.rolling(window=period).mean()
    
    @staticmethod
    def ema(prices: pd.Series, period: int) -> pd.Series:
        """Exponential Moving Average"""
        return prices.ewm(span=period, adjust=False).mean()
    
    @staticmethod
    def rsi(prices: pd.Series, period: int = 14) -> pd.Series:
        """
        Relative Strength Index
        
        RSI = 100 - (100 / (1 + RS))
        where RS = Average Gain / Average Loss
        """
        delta = prices.diff()
        gain = delta.where(delta > 0, 0).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs))
    
    @staticmethod
    def macd(prices: pd.Series, 
             fast: int = 12, 
             slow: int = 26, 
             signal: int = 9) -> Tuple[pd.Series, pd.Series, pd.Series]:
        """
        Moving Average Convergence Divergence
        
        Returns: (macd_line, signal_line, histogram)
        """
        ema_fast = prices.ewm(span=fast, adjust=False).mean()
        ema_slow = prices.ewm(span=slow, adjust=False).mean()
        macd_line = ema_fast - ema_slow
        signal_line = macd_line.ewm(span=signal, adjust=False).mean()
        histogram = macd_line - signal_line
        return macd_line, signal_line, histogram
    
    @staticmethod
    def bollinger_bands(prices: pd.Series, 
                        period: int = 20, 
                        std_dev: float = 2.0) -> Tuple[pd.Series, pd.Series, pd.Series]:
        """
        Bollinger Bands for mean reversion strategies
        
        Returns: (upper_band, middle_band, lower_band)
        """
        middle = prices.rolling(window=period).mean()
        std = prices.rolling(window=period).std()
        upper = middle + (std_dev * std)
        lower = middle - (std_dev * std)
        return upper, middle, lower
    
    @staticmethod
    def atr(high: pd.Series, 
            low: pd.Series, 
            close: pd.Series, 
            period: int = 14) -> pd.Series:
        """
        Average True Range - volatility indicator
        
        Used for position sizing and stop-loss placement
        """
        tr1 = high - low
        tr2 = abs(high - close.shift(1))
        tr3 = abs(low - close.shift(1))
        true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        return true_range.rolling(window=period).mean()
    
    @staticmethod
    def stochastic_oscillator(high: pd.Series, 
                              low: pd.Series, 
                              close: pd.Series, 
                              k_period: int = 14, 
                              d_period: int = 3) -> Tuple[pd.Series, pd.Series]:
        """
        Stochastic Oscillator
        
        %K = (Close - Lowest Low) / (Highest High - Lowest Low) * 100
        %D = 3-period SMA of %K
        """
        lowest_low = low.rolling(window=k_period).min()
        highest_high = high.rolling(window=k_period).max()
        k = ((close - lowest_low) / (highest_high - lowest_low)) * 100
        d = k.rolling(window=d_period).mean()
        return k, d
\end{lstlisting}

\subsection{Advanced Feature Engineering}

For machine learning models, additional feature engineering techniques from López de Prado's \textit{Advances in Financial Machine Learning} are implemented:

\begin{lstlisting}[caption={Advanced Feature Engineering for ML}, label={lst:advanced-features}]
class AdvancedFeatures:
    """
    Advanced feature engineering techniques from 
    'Advances in Financial Machine Learning' by Marcos Lopez de Prado
    """
    
    @staticmethod
    def fractional_diff(series: pd.Series, 
                        d: float = 0.4, 
                        threshold: float = 1e-5) -> pd.Series:
        """
        Fractional differentiation to maintain memory while 
        achieving stationarity.
        
        This technique preserves long-term dependencies in the data
        while making it stationary for ML models.
        
        Parameters:
            series: Price series to differentiate
            d: Differentiation order (0 < d < 1)
            threshold: Weight threshold for truncation
        """
        weights = [1.0]
        k = 1
        while abs(weights[-1]) > threshold:
            weight = -weights[-1] * (d - k + 1) / k
            weights.append(weight)
            k += 1
        weights = np.array(weights[::-1])
        
        result = []
        for i in range(len(weights) - 1, len(series)):
            window = series.iloc[i - len(weights) + 1:i + 1].values
            result.append(np.dot(weights, window))
        
        return pd.Series(
            result, 
            index=series.index[len(weights) - 1:]
        )
    
    @staticmethod
    def compute_dollar_bars(trades: pd.DataFrame, 
                           dollar_threshold: float) -> pd.DataFrame:
        """
        Dollar bars: sample data when cumulative dollar volume
        reaches a threshold. This normalizes for varying trading
        activity across time.
        """
        trades['dollar_volume'] = trades['price'] * trades['volume']
        trades['cum_dollar'] = trades['dollar_volume'].cumsum()
        
        bars = []
        current_bar = {'open': None, 'high': -np.inf, 
                       'low': np.inf, 'volume': 0}
        last_threshold = 0
        
        for _, trade in trades.iterrows():
            if current_bar['open'] is None:
                current_bar['open'] = trade['price']
            
            current_bar['high'] = max(current_bar['high'], trade['price'])
            current_bar['low'] = min(current_bar['low'], trade['price'])
            current_bar['volume'] += trade['volume']
            current_bar['close'] = trade['price']
            current_bar['timestamp'] = trade['timestamp']
            
            if trade['cum_dollar'] - last_threshold >= dollar_threshold:
                bars.append(current_bar.copy())
                last_threshold = trade['cum_dollar']
                current_bar = {'open': None, 'high': -np.inf, 
                              'low': np.inf, 'volume': 0}
        
        return pd.DataFrame(bars)
    
    @staticmethod
    def get_entropy(series: pd.Series, bins: int = 10) -> float:
        """
        Shannon entropy for measuring information content
        in a price series.
        """
        counts, _ = np.histogram(series, bins=bins)
        probs = counts / len(series)
        probs = probs[probs > 0]  # Remove zeros
        return -np.sum(probs * np.log2(probs))
\end{lstlisting}

% ============================================================================
% CHAPTER 5: STRATEGY DEVELOPMENT
% ============================================================================

\chapter{Strategy Development}
\label{ch:strategy-development}

\section{Strategy Framework Design}

All trading strategies inherit from a common base class that enforces consistent interfaces and behavior.

\begin{lstlisting}[caption={Strategy Base Class}, label={lst:base-strategy}]
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from enum import Enum
from typing import Dict, List, Optional
import pandas as pd

class SignalType(Enum):
    """Trading signal types"""
    BUY = "BUY"
    SELL = "SELL"
    HOLD = "HOLD"

@dataclass
class Signal:
    """
    Trading signal generated by a strategy
    
    Attributes:
        symbol: Stock ticker symbol
        signal_type: BUY, SELL, or HOLD
        strength: Confidence score from 0.0 to 1.0
        timestamp: When the signal was generated
        metadata: Additional context (reason, indicators used, etc.)
    """
    symbol: str
    signal_type: SignalType
    strength: float
    timestamp: pd.Timestamp
    metadata: Dict = field(default_factory=dict)
    
    def __post_init__(self):
        if not 0.0 <= self.strength <= 1.0:
            raise ValueError("Signal strength must be between 0 and 1")

class BaseStrategy(ABC):
    """
    Abstract base class for all trading strategies.
    
    This design is inspired by systematic approaches described in 
    Ernie Chan's 'Algorithmic Trading: Winning Strategies and 
    Their Rationale'.
    """
    
    def __init__(self, 
                 name: str, 
                 universe: List[str], 
                 params: Optional[Dict] = None):
        self.name = name
        self.universe = universe
        self.params = params or {}
        self.positions: Dict[str, int] = {}
        self._is_active = True
        
    @abstractmethod
    def generate_signals(self, 
                         market_data: pd.DataFrame) -> List[Signal]:
        """
        Generate trading signals based on market data.
        
        Must be implemented by all concrete strategies.
        
        Args:
            market_data: DataFrame with OHLCV data for all symbols
            
        Returns:
            List of Signal objects
        """
        pass
    
    @abstractmethod
    def calculate_position_size(self, 
                                signal: Signal, 
                                portfolio_value: float,
                                current_price: float) -> int:
        """
        Determine position size for a given signal.
        
        Args:
            signal: The trading signal
            portfolio_value: Total portfolio value
            current_price: Current price of the security
            
        Returns:
            Number of shares to trade
        """
        pass
    
    def validate_signal(self, signal: Signal) -> bool:
        """
        Apply validation rules before acting on a signal.
        
        Can be overridden by subclasses for custom validation.
        """
        min_strength = self.params.get('min_signal_strength', 0.5)
        return signal.strength >= min_strength
    
    def activate(self):
        """Enable the strategy"""
        self._is_active = True
        
    def deactivate(self):
        """Disable the strategy without affecting positions"""
        self._is_active = False
    
    @property
    def is_active(self) -> bool:
        return self._is_active
\end{lstlisting}

\section{CAN SLIM Strategy Implementation}

The CAN SLIM strategy implements William O'Neil's proven 7-step process from \textit{How to Make Money in Stocks}.

\begin{conceptbox}{CAN SLIM Criteria}
\begin{itemize}[leftmargin=*, nosep]
    \item \textbf{C} -- Current quarterly earnings per share (up 25\%+)
    \item \textbf{A} -- Annual earnings growth (25\%+ over 5 years)
    \item \textbf{N} -- New products, management, or price highs
    \item \textbf{S} -- Supply and demand (shares outstanding + volume)
    \item \textbf{L} -- Leader or laggard (relative strength ranking)
    \item \textbf{I} -- Institutional sponsorship (10-60\% ownership)
    \item \textbf{M} -- Market direction (follow the general market)
\end{itemize}
\end{conceptbox}

\begin{lstlisting}[caption={CAN SLIM Strategy Implementation}, label={lst:canslim}]
class CANSLIMStrategy(BaseStrategy):
    """
    Implementation of William O'Neil's CAN SLIM system from 
    'How to Make Money in Stocks'.
    
    This strategy identifies growth stocks with strong fundamentals
    and technical momentum at optimal buying points.
    """
    
    def __init__(self, universe: List[str]):
        super().__init__(
            name="CANSLIM",
            universe=universe,
            params={
                'min_eps_growth_qoq': 0.25,      # 25% quarterly
                'min_eps_growth_annual': 0.25,   # 25% annual
                'min_relative_strength': 80,     # RS rank >= 80
                'min_institutional': 0.10,       # 10% institutional
                'max_institutional': 0.60,       # Not over-owned
                'volume_surge_ratio': 1.5,       # 50% above average
                'price_to_52w_high': 0.95,       # Within 5% of high
            }
        )
        self.market_direction = None  # M factor
    
    def _score_c_factor(self, fundamentals: Dict) -> float:
        """Score current quarterly earnings"""
        eps_growth = fundamentals.get('eps_growth_qoq', 0)
        if eps_growth >= self.params['min_eps_growth_qoq']:
            # Higher growth = higher score
            return min(1.0, eps_growth / 0.50)  # Cap at 50% growth
        return 0.0
    
    def _score_a_factor(self, fundamentals: Dict) -> float:
        """Score annual earnings growth"""
        annual_growth = fundamentals.get('eps_growth_annual_5yr', 0)
        if annual_growth >= self.params['min_eps_growth_annual']:
            return min(1.0, annual_growth / 0.50)
        return 0.0
    
    def _score_n_factor(self, 
                        fundamentals: Dict, 
                        technicals: Dict) -> float:
        """Score new highs and catalysts"""
        score = 0.0
        
        # Near 52-week high
        price_vs_high = technicals.get('price_vs_52w_high', 0)
        if price_vs_high >= self.params['price_to_52w_high']:
            score += 0.5
        
        # New product or catalyst (if available)
        if fundamentals.get('has_recent_catalyst', False):
            score += 0.5
        
        return score
    
    def _score_s_factor(self, technicals: Dict) -> float:
        """Score supply and demand (volume analysis)"""
        volume_ratio = technicals.get('volume_vs_avg', 1.0)
        if volume_ratio >= self.params['volume_surge_ratio']:
            return min(1.0, (volume_ratio - 1.0) / 1.0)
        return 0.0
    
    def _score_l_factor(self, technicals: Dict) -> float:
        """Score leadership (relative strength)"""
        rs_rank = technicals.get('relative_strength_rank', 0)
        if rs_rank >= self.params['min_relative_strength']:
            return (rs_rank - 80) / 20  # Scale 80-100 to 0-1
        return 0.0
    
    def _score_i_factor(self, fundamentals: Dict) -> float:
        """Score institutional sponsorship"""
        inst_ownership = fundamentals.get('institutional_ownership', 0)
        min_inst = self.params['min_institutional']
        max_inst = self.params['max_institutional']
        
        if min_inst <= inst_ownership <= max_inst:
            # Optimal range gets full score
            return 1.0
        elif inst_ownership < min_inst:
            return inst_ownership / min_inst
        else:
            # Over-owned is negative
            return max(0, 1 - (inst_ownership - max_inst) / 0.20)
    
    def _check_m_factor(self) -> bool:
        """Check market direction (requires separate analysis)"""
        # In practice, this would check:
        # - Major indices above 50-day MA
        # - Number of new highs vs new lows
        # - Distribution days count
        return self.market_direction in ['uptrend', 'confirmed_uptrend']
    
    def score_stock(self, 
                    fundamentals: Dict, 
                    technicals: Dict) -> float:
        """
        Calculate overall CAN SLIM score for a stock.
        
        Returns score from 0.0 to 1.0
        """
        scores = {
            'C': self._score_c_factor(fundamentals),
            'A': self._score_a_factor(fundamentals),
            'N': self._score_n_factor(fundamentals, technicals),
            'S': self._score_s_factor(technicals),
            'L': self._score_l_factor(technicals),
            'I': self._score_i_factor(fundamentals),
        }
        
        # Weighted average (L is most important per O'Neil)
        weights = {'C': 0.15, 'A': 0.15, 'N': 0.10, 
                   'S': 0.15, 'L': 0.25, 'I': 0.20}
        
        total_score = sum(
            scores[factor] * weights[factor] 
            for factor in scores
        )
        
        return total_score
    
    def generate_signals(self, 
                         market_data: pd.DataFrame) -> List[Signal]:
        """Generate CAN SLIM buy signals"""
        signals = []
        
        # Check market direction first (M factor)
        if not self._check_m_factor():
            return signals  # No buys in downtrend
        
        for symbol in self.universe:
            # Get fundamentals and technicals for symbol
            fundamentals = self._get_fundamentals(symbol)
            technicals = self._calculate_technicals(
                market_data[market_data['symbol'] == symbol]
            )
            
            score = self.score_stock(fundamentals, technicals)
            
            if score >= 0.7:  # Strong candidate
                signals.append(Signal(
                    symbol=symbol,
                    signal_type=SignalType.BUY,
                    strength=score,
                    timestamp=pd.Timestamp.now(),
                    metadata={
                        'strategy': 'CANSLIM',
                        'factors': self._get_factor_breakdown(
                            fundamentals, technicals
                        )
                    }
                ))
        
        return signals
    
    def calculate_position_size(self, 
                                signal: Signal, 
                                portfolio_value: float,
                                current_price: float) -> int:
        """
        Position sizing based on signal strength and O'Neil's
        pyramid buying approach.
        """
        # Base allocation: 5-10% of portfolio per position
        base_pct = 0.05 + (signal.strength - 0.7) * 0.15
        allocation = portfolio_value * base_pct
        shares = int(allocation / current_price)
        return shares
\end{lstlisting}

\section{Mean Reversion Strategy}

Mean reversion strategies capitalize on the tendency of prices to return to their historical averages.

\begin{lstlisting}[caption={Mean Reversion Strategy Implementation}, label={lst:mean-reversion}]
class MeanReversionStrategy(BaseStrategy):
    """
    Bollinger Band mean reversion strategy based on concepts 
    from 'Technical Analysis of the Financial Markets' by Murphy
    and 'Technical Analysis Explained' by Pring.
    
    This strategy buys when price is oversold (below lower band)
    and sells when overbought (above upper band).
    """
    
    def __init__(self, universe: List[str]):
        super().__init__(
            name="MeanReversion",
            universe=universe,
            params={
                'bb_period': 20,
                'bb_std': 2.0,
                'rsi_period': 14,
                'rsi_oversold': 30,
                'rsi_overbought': 70,
                'min_holding_period': 5,  # days
                'profit_target': 0.05,    # 5%
                'stop_loss': 0.03,        # 3%
            }
        )
        self.entry_prices: Dict[str, float] = {}
        self.entry_dates: Dict[str, pd.Timestamp] = {}
    
    def generate_signals(self, 
                         market_data: pd.DataFrame) -> List[Signal]:
        """Generate mean reversion signals"""
        signals = []
        
        for symbol in self.universe:
            symbol_data = market_data[
                market_data['symbol'] == symbol
            ].copy()
            
            if len(symbol_data) < self.params['bb_period']:
                continue
            
            prices = symbol_data['close']
            
            # Calculate indicators
            upper, middle, lower = TechnicalIndicators.bollinger_bands(
                prices,
                self.params['bb_period'],
                self.params['bb_std']
            )
            rsi = TechnicalIndicators.rsi(
                prices, 
                self.params['rsi_period']
            )
            
            current_price = prices.iloc[-1]
            current_rsi = rsi.iloc[-1]
            current_upper = upper.iloc[-1]
            current_lower = lower.iloc[-1]
            current_middle = middle.iloc[-1]
            
            # Check for existing position
            has_position = symbol in self.entry_prices
            
            if has_position:
                # Check exit conditions
                signal = self._check_exit(
                    symbol, current_price, current_rsi,
                    current_upper, current_middle
                )
                if signal:
                    signals.append(signal)
            else:
                # Check entry conditions
                signal = self._check_entry(
                    symbol, current_price, current_rsi,
                    current_lower, current_upper
                )
                if signal:
                    signals.append(signal)
        
        return signals
    
    def _check_entry(self, 
                     symbol: str,
                     price: float,
                     rsi: float,
                     lower_band: float,
                     upper_band: float) -> Optional[Signal]:
        """Check for entry conditions"""
        
        # Long entry: price below lower band + RSI oversold
        if price < lower_band and rsi < self.params['rsi_oversold']:
            # Strength based on how far below band
            deviation = (lower_band - price) / price
            strength = min(1.0, deviation / 0.05)  # Cap at 5% deviation
            
            return Signal(
                symbol=symbol,
                signal_type=SignalType.BUY,
                strength=strength,
                timestamp=pd.Timestamp.now(),
                metadata={
                    'strategy': 'MeanReversion',
                    'entry_type': 'oversold_bounce',
                    'rsi': rsi,
                    'bb_position': 'below_lower'
                }
            )
        
        return None
    
    def _check_exit(self,
                    symbol: str,
                    price: float,
                    rsi: float,
                    upper_band: float,
                    middle_band: float) -> Optional[Signal]:
        """Check for exit conditions"""
        
        entry_price = self.entry_prices.get(symbol, price)
        pnl_pct = (price - entry_price) / entry_price
        
        # Exit conditions:
        # 1. Price above upper band (overbought)
        # 2. RSI overbought
        # 3. Profit target reached
        # 4. Stop loss triggered
        
        should_exit = (
            (price > upper_band and rsi > self.params['rsi_overbought']) or
            pnl_pct >= self.params['profit_target'] or
            pnl_pct <= -self.params['stop_loss']
        )
        
        if should_exit:
            return Signal(
                symbol=symbol,
                signal_type=SignalType.SELL,
                strength=1.0,  # Full exit
                timestamp=pd.Timestamp.now(),
                metadata={
                    'strategy': 'MeanReversion',
                    'exit_type': self._determine_exit_type(
                        price, upper_band, rsi, pnl_pct
                    ),
                    'pnl_pct': pnl_pct
                }
            )
        
        return None
    
    def _determine_exit_type(self, 
                             price: float, 
                             upper: float,
                             rsi: float,
                             pnl: float) -> str:
        """Determine the reason for exit"""
        if pnl >= self.params['profit_target']:
            return 'profit_target'
        elif pnl <= -self.params['stop_loss']:
            return 'stop_loss'
        elif price > upper:
            return 'overbought'
        else:
            return 'other'
    
    def calculate_position_size(self,
                                signal: Signal,
                                portfolio_value: float,
                                current_price: float) -> int:
        """
        Position sizing with volatility adjustment.
        
        Mean reversion positions are sized inversely to recent
        volatility to maintain consistent risk.
        """
        base_allocation = 0.10 * signal.strength
        allocation = portfolio_value * base_allocation
        shares = int(allocation / current_price)
        return shares
\end{lstlisting}

% ============================================================================
% CHAPTER 6: BACKTESTING FRAMEWORK
% ============================================================================

\chapter{Backtesting Framework}
\label{ch:backtesting}

\section{Backtester Design Principles}

A robust backtesting framework is essential for strategy validation. The design follows principles from Ernie Chan's \textit{Algorithmic Trading} and Kevin Davey's \textit{Building Winning Algorithmic Trading Systems}.

\begin{warningbox}
\textbf{Common Backtesting Pitfalls to Avoid:}
\begin{enumerate}[nosep]
    \item \textbf{Look-ahead bias}: Using information not available at decision time
    \item \textbf{Survivorship bias}: Only testing on stocks that still exist
    \item \textbf{Overfitting}: Optimizing parameters to historical noise
    \item \textbf{Ignoring costs}: Not accounting for commissions and slippage
    \item \textbf{Data snooping}: Testing too many variations on same data
\end{enumerate}
\end{warningbox}

\section{Backtester Implementation}

\begin{lstlisting}[caption={Backtester Core Implementation}, label={lst:backtester}]
from dataclasses import dataclass
from typing import List, Dict, Optional
import pandas as pd
import numpy as np

@dataclass
class BacktestConfig:
    """Configuration for backtest execution"""
    start_date: str
    end_date: str
    initial_capital: float
    commission_rate: float = 0.001   # 0.1% per trade
    slippage_model: str = "fixed"    # fixed, percentage, volume
    slippage_bps: float = 5.0        # basis points
    margin_requirement: float = 1.0  # 1.0 = no margin

@dataclass
class BacktestResults:
    """Container for backtest performance metrics"""
    total_return: float
    annualized_return: float
    sharpe_ratio: float
    sortino_ratio: float
    max_drawdown: float
    calmar_ratio: float
    win_rate: float
    profit_factor: float
    total_trades: int
    avg_trade_duration: float
    equity_curve: pd.Series
    drawdown_series: pd.Series
    trades: pd.DataFrame
    monthly_returns: pd.Series

class EventDrivenBacktester:
    """
    Event-driven backtesting engine.
    
    This architecture processes market events chronologically,
    simulating realistic order fills and portfolio updates.
    """
    
    def __init__(self, config: BacktestConfig):
        self.config = config
        self.portfolio = SimulatedPortfolio(config.initial_capital)
        self.trades: List[Dict] = []
        self.equity_history: List[Dict] = []
        self.slippage_model = self._create_slippage_model()
    
    def _create_slippage_model(self) -> 'SlippageModel':
        """Factory method for slippage models"""
        if self.config.slippage_model == "fixed":
            return FixedSlippage(self.config.slippage_bps)
        elif self.config.slippage_model == "percentage":
            return PercentageSlippage(self.config.slippage_bps)
        elif self.config.slippage_model == "volume":
            return VolumeBasedSlippage(self.config.slippage_bps)
        else:
            raise ValueError(f"Unknown slippage model")
    
    def run(self, 
            strategy: BaseStrategy, 
            market_data: pd.DataFrame) -> BacktestResults:
        """
        Execute backtest simulation.
        
        Args:
            strategy: Strategy instance to test
            market_data: Historical OHLCV data
            
        Returns:
            BacktestResults with performance metrics
        """
        # Sort data chronologically
        market_data = market_data.sort_values('timestamp')
        dates = market_data['timestamp'].dt.date.unique()
        
        for date in dates:
            # Get data up to current date (no look-ahead)
            historical_data = market_data[
                market_data['timestamp'].dt.date <= date
            ]
            current_data = market_data[
                market_data['timestamp'].dt.date == date
            ]
            
            # Generate signals using only historical data
            signals = strategy.generate_signals(historical_data)
            
            # Execute valid signals
            for signal in signals:
                if strategy.validate_signal(signal):
                    self._execute_signal(signal, current_data)
            
            # Update portfolio mark-to-market
            self._update_portfolio(current_data)
            
            # Record equity
            self.equity_history.append({
                'date': date,
                'equity': self.portfolio.total_value,
                'cash': self.portfolio.cash,
                'positions_value': self.portfolio.positions_value
            })
        
        return self._calculate_results()
    
    def _execute_signal(self, 
                        signal: Signal, 
                        current_data: pd.DataFrame):
        """Execute a trading signal with realistic fills"""
        
        symbol_data = current_data[
            current_data['symbol'] == signal.symbol
        ]
        
        if symbol_data.empty:
            return
        
        # Use open price for fill (next bar execution)
        base_price = symbol_data['open'].iloc[0]
        volume = symbol_data['volume'].iloc[0]
        
        # Apply slippage
        fill_price = self.slippage_model.apply(
            base_price, 
            signal.signal_type, 
            volume
        )
        
        # Calculate position size
        position_size = self._calculate_shares(
            signal, fill_price
        )
        
        if position_size == 0:
            return
        
        # Calculate commission
        commission = abs(position_size * fill_price * 
                        self.config.commission_rate)
        
        # Execute trade
        if signal.signal_type == SignalType.BUY:
            cost = position_size * fill_price + commission
            if cost <= self.portfolio.cash:
                self.portfolio.buy(
                    signal.symbol, position_size, fill_price
                )
                self.portfolio.cash -= commission
                self._record_trade(
                    signal, position_size, fill_price, commission
                )
        
        elif signal.signal_type == SignalType.SELL:
            current_position = self.portfolio.get_position(signal.symbol)
            if current_position > 0:
                sell_qty = min(position_size, current_position)
                self.portfolio.sell(
                    signal.symbol, sell_qty, fill_price
                )
                self.portfolio.cash -= commission
                self._record_trade(
                    signal, -sell_qty, fill_price, commission
                )
    
    def _calculate_results(self) -> BacktestResults:
        """Calculate comprehensive performance metrics"""
        
        equity_df = pd.DataFrame(self.equity_history)
        equity = equity_df['equity']
        
        # Daily returns
        returns = equity.pct_change().dropna()
        
        # Total and annualized return
        total_return = (equity.iloc[-1] / equity.iloc[0]) - 1
        n_days = len(returns)
        annualized_return = (1 + total_return) ** (252 / n_days) - 1
        
        # Risk metrics
        volatility = returns.std() * np.sqrt(252)
        sharpe_ratio = (annualized_return / volatility 
                        if volatility > 0 else 0)
        
        # Sortino (downside deviation)
        downside_returns = returns[returns < 0]
        downside_std = downside_returns.std() * np.sqrt(252)
        sortino_ratio = (annualized_return / downside_std 
                         if downside_std > 0 else 0)
        
        # Drawdown analysis
        cumulative = (1 + returns).cumprod()
        running_max = cumulative.expanding().max()
        drawdown = (cumulative - running_max) / running_max
        max_drawdown = drawdown.min()
        
        # Calmar ratio
        calmar_ratio = (annualized_return / abs(max_drawdown) 
                        if max_drawdown != 0 else 0)
        
        # Trade analysis
        trades_df = pd.DataFrame(self.trades)
        if len(trades_df) > 0:
            trades_df['pnl'] = self._calculate_trade_pnl(trades_df)
            winning = trades_df[trades_df['pnl'] > 0]
            losing = trades_df[trades_df['pnl'] < 0]
            
            win_rate = len(winning) / len(trades_df)
            
            gross_profit = winning['pnl'].sum() if len(winning) > 0 else 0
            gross_loss = abs(losing['pnl'].sum()) if len(losing) > 0 else 1
            profit_factor = gross_profit / gross_loss
            
            avg_duration = trades_df['duration'].mean()
        else:
            win_rate = 0
            profit_factor = 0
            avg_duration = 0
            trades_df = pd.DataFrame()
        
        # Monthly returns
        equity_df['date'] = pd.to_datetime(equity_df['date'])
        monthly = equity_df.set_index('date')['equity'].resample('M').last()
        monthly_returns = monthly.pct_change().dropna()
        
        return BacktestResults(
            total_return=total_return,
            annualized_return=annualized_return,
            sharpe_ratio=sharpe_ratio,
            sortino_ratio=sortino_ratio,
            max_drawdown=max_drawdown,
            calmar_ratio=calmar_ratio,
            win_rate=win_rate,
            profit_factor=profit_factor,
            total_trades=len(self.trades),
            avg_trade_duration=avg_duration,
            equity_curve=equity,
            drawdown_series=drawdown,
            trades=trades_df,
            monthly_returns=monthly_returns
        )
\end{lstlisting}

\section{Walk-Forward Optimization}

Walk-forward analysis prevents overfitting by validating optimized parameters on unseen data.

\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[
        insample/.style={fill=blue!30, draw=primaryblue, thick},
        outsample/.style={fill=green!30, draw=accentgreen, thick},
        label/.style={font=\small}
    ]
        % Title
        \node[font=\bfseries, primaryblue] at (5,4) {Walk-Forward Optimization Timeline};
        
        % Fold 1
        \draw[insample] (0,3) rectangle (4,3.5);
        \draw[outsample] (4,3) rectangle (5.5,3.5);
        \node[label, left] at (0,3.25) {Fold 1};
        
        % Fold 2
        \draw[insample] (1.5,2) rectangle (5.5,2.5);
        \draw[outsample] (5.5,2) rectangle (7,2.5);
        \node[label, left] at (0,2.25) {Fold 2};
        
        % Fold 3
        \draw[insample] (3,1) rectangle (7,1.5);
        \draw[outsample] (7,1) rectangle (8.5,1.5);
        \node[label, left] at (0,1.25) {Fold 3};
        
        % Fold 4
        \draw[insample] (4.5,0) rectangle (8.5,0.5);
        \draw[outsample] (8.5,0) rectangle (10,0.5);
        \node[label, left] at (0,0.25) {Fold 4};
        
        % Legend
        \draw[insample] (0,-1) rectangle (0.5,-0.7);
        \node[label, right] at (0.6,-0.85) {In-Sample (Optimization)};
        \draw[outsample] (4,-1) rectangle (4.5,-0.7);
        \node[label, right] at (4.6,-0.85) {Out-of-Sample (Validation)};
        
        % Time arrow
        \draw[-Stealth, thick] (0,-1.5) -- (10,-1.5);
        \node[label] at (5,-1.8) {Time};
        
    \end{tikzpicture}
    \caption{Walk-Forward Optimization Process}
    \label{fig:walk-forward}
\end{figure}

\begin{lstlisting}[caption={Walk-Forward Optimizer Implementation}, label={lst:walk-forward}]
class WalkForwardOptimizer:
    """
    Walk-forward optimization to prevent overfitting.
    
    This technique is recommended in Kevin Davey's 
    'Building Winning Algorithmic Trading Systems'.
    """
    
    def __init__(self, 
                 in_sample_pct: float = 0.70,
                 num_folds: int = 5,
                 embargo_periods: int = 5):
        """
        Args:
            in_sample_pct: Percentage of each fold for optimization
            num_folds: Number of walk-forward folds
            embargo_periods: Gap between in-sample and out-of-sample
        """
        self.in_sample_pct = in_sample_pct
        self.num_folds = num_folds
        self.embargo_periods = embargo_periods
    
    def optimize(self,
                 strategy_class: type,
                 param_grid: Dict,
                 market_data: pd.DataFrame,
                 objective: str = 'sharpe') -> Dict:
        """
        Perform walk-forward optimization.
        
        Args:
            strategy_class: Strategy class to optimize
            param_grid: Dictionary of parameter ranges
            market_data: Historical market data
            objective: Optimization metric ('sharpe', 'return', 'calmar')
            
        Returns:
            Dictionary with optimization results
        """
        results = []
        fold_size = len(market_data) // self.num_folds
        
        for fold in range(self.num_folds):
            fold_start = fold * fold_size
            fold_end = min(fold_start + fold_size, len(market_data))
            
            # Calculate split point
            in_sample_end = fold_start + int(
                (fold_end - fold_start) * self.in_sample_pct
            )
            
            # Apply embargo gap
            out_sample_start = in_sample_end + self.embargo_periods
            
            # Split data
            in_sample = market_data.iloc[fold_start:in_sample_end]
            out_sample = market_data.iloc[out_sample_start:fold_end]
            
            if len(out_sample) < 20:  # Minimum validation period
                continue
            
            # Grid search on in-sample
            best_params, is_results = self._grid_search(
                strategy_class, param_grid, in_sample, objective
            )
            
            # Validate on out-of-sample
            oos_results = self._validate(
                strategy_class, best_params, out_sample
            )
            
            results.append({
                'fold': fold,
                'best_params': best_params,
                'in_sample_sharpe': is_results['sharpe_ratio'],
                'in_sample_return': is_results['total_return'],
                'out_sample_sharpe': oos_results.sharpe_ratio,
                'out_sample_return': oos_results.total_return,
                'degradation': (
                    is_results['sharpe_ratio'] - oos_results.sharpe_ratio
                ) / is_results['sharpe_ratio'] if is_results['sharpe_ratio'] > 0 else 0
            })
        
        return self._aggregate_results(results)
    
    def _grid_search(self,
                     strategy_class: type,
                     param_grid: Dict,
                     data: pd.DataFrame,
                     objective: str) -> tuple:
        """Exhaustive grid search for optimal parameters"""
        
        from itertools import product
        
        # Generate all parameter combinations
        keys = param_grid.keys()
        values = param_grid.values()
        combinations = list(product(*values))
        
        best_score = -np.inf
        best_params = None
        best_results = None
        
        for combo in combinations:
            params = dict(zip(keys, combo))
            
            # Create and test strategy
            strategy = strategy_class(
                universe=data['symbol'].unique().tolist(),
                params=params
            )
            
            backtester = EventDrivenBacktester(BacktestConfig(
                start_date=str(data['timestamp'].min()),
                end_date=str(data['timestamp'].max()),
                initial_capital=100000
            ))
            
            results = backtester.run(strategy, data)
            
            # Get objective score
            score = getattr(results, f'{objective}_ratio' 
                           if objective != 'return' 
                           else 'total_return')
            
            if score > best_score:
                best_score = score
                best_params = params
                best_results = {
                    'sharpe_ratio': results.sharpe_ratio,
                    'total_return': results.total_return
                }
        
        return best_params, best_results
    
    def _aggregate_results(self, results: List[Dict]) -> Dict:
        """Aggregate results across all folds"""
        
        df = pd.DataFrame(results)
        
        return {
            'folds': results,
            'avg_oos_sharpe': df['out_sample_sharpe'].mean(),
            'std_oos_sharpe': df['out_sample_sharpe'].std(),
            'avg_degradation': df['degradation'].mean(),
            'consistent_params': self._find_consistent_params(results),
            'robustness_score': self._calculate_robustness(df)
        }
    
    def _calculate_robustness(self, df: pd.DataFrame) -> float:
        """
        Calculate strategy robustness score.
        
        A robust strategy should have:
        - Positive OOS Sharpe across all folds
        - Low degradation from IS to OOS
        - Consistent performance
        """
        positive_folds = (df['out_sample_sharpe'] > 0).mean()
        avg_sharpe = df['out_sample_sharpe'].mean()
        consistency = 1 - df['out_sample_sharpe'].std() / abs(avg_sharpe) \
                      if avg_sharpe != 0 else 0
        low_degradation = (df['degradation'] < 0.5).mean()
        
        return (positive_folds + consistency + low_degradation) / 3
\end{lstlisting}

% ============================================================================
% CHAPTER 7: RISK MANAGEMENT
% ============================================================================

\chapter{Risk Management}
\label{ch:risk-management}

\section{Risk Management Philosophy}

Risk management is the cornerstone of successful algorithmic trading. As Mark Douglas emphasizes in \textit{Trading in the Zone}, maintaining discipline and controlling risk is more important than finding the perfect entry.

\begin{conceptbox}{Key Risk Principles}
\begin{enumerate}[nosep]
    \item Never risk more than 2\% of capital on a single trade
    \item Use position sizing to normalize risk across different volatility levels
    \item Implement automated stops to remove emotional decision-making
    \item Monitor correlation to avoid concentrated sector bets
    \item Have circuit breakers for extreme drawdowns
\end{enumerate}
\end{conceptbox}

\section{Risk Manager Implementation}

\begin{lstlisting}[caption={Comprehensive Risk Manager}, label={lst:risk-manager}]
from typing import Tuple, Dict, Optional
import numpy as np

class RiskManager:
    """
    Comprehensive risk management system.
    
    Implements principles from 'Trading in the Zone' (Douglas)
    regarding discipline and emotional control through systematic
    rule enforcement.
    """
    
    def __init__(self, config: Dict):
        """
        Initialize risk manager with configuration.
        
        Args:
            config: Dictionary with risk parameters
        """
        # Position-level limits
        self.max_position_pct = config.get('max_position_pct', 0.10)
        self.max_risk_per_trade = config.get('max_risk_per_trade', 0.02)
        
        # Portfolio-level limits
        self.max_portfolio_risk = config.get('max_portfolio_risk', 0.06)
        self.max_sector_exposure = config.get('max_sector_exposure', 0.30)
        self.max_correlation = config.get('max_correlation', 0.70)
        self.max_positions = config.get('max_positions', 20)
        
        # Stop-loss settings
        self.default_stop_pct = config.get('default_stop_pct', 0.05)
        self.trailing_stop_pct = config.get('trailing_stop_pct', 0.08)
        
        # Circuit breakers
        self.daily_loss_limit = config.get('daily_loss_limit', 0.03)
        self.weekly_loss_limit = config.get('weekly_loss_limit', 0.06)
        self.max_drawdown_halt = config.get('max_drawdown_halt', 0.15)
        
        # State tracking
        self.daily_pnl = 0.0
        self.weekly_pnl = 0.0
        self.is_halted = False
        self.halt_reason: Optional[str] = None
    
    def calculate_position_size(self,
                                signal: 'Signal',
                                portfolio_value: float,
                                current_price: float,
                                volatility: float,
                                stop_price: Optional[float] = None
                                ) -> int:
        """
        Calculate appropriate position size using multiple methods.
        
        Implements:
        1. Fixed fractional (risk per trade)
        2. Volatility-adjusted sizing
        3. Kelly Criterion (optional)
        
        Returns the most conservative of all methods.
        """
        sizes = []
        
        # Method 1: Fixed fractional based on stop loss
        if stop_price:
            risk_per_share = abs(current_price - stop_price)
            dollar_risk = portfolio_value * self.max_risk_per_trade
            fixed_fractional_size = int(dollar_risk / risk_per_share)
            sizes.append(fixed_fractional_size)
        
        # Method 2: Maximum position size limit
        max_allocation = portfolio_value * self.max_position_pct
        max_position_size = int(max_allocation / current_price)
        sizes.append(max_position_size)
        
        # Method 3: Volatility-adjusted sizing
        target_vol = 0.20  # Target 20% annualized volatility
        vol_scalar = target_vol / volatility if volatility > 0 else 1.0
        vol_allocation = portfolio_value * 0.10 * vol_scalar * signal.strength
        vol_adjusted_size = int(vol_allocation / current_price)
        sizes.append(vol_adjusted_size)
        
        # Return most conservative size
        return max(0, min(sizes))
    
    def check_trade_allowed(self,
                           signal: 'Signal',
                           portfolio: 'Portfolio',
                           position_size: int,
                           current_price: float,
                           sector_map: Dict[str, str]
                           ) -> Tuple[bool, str]:
        """
        Comprehensive pre-trade risk checks.
        
        Returns:
            Tuple of (allowed: bool, reason: str)
        """
        # Check circuit breakers first
        if self.is_halted:
            return False, f"Trading halted: {self.halt_reason}"
        
        # Check daily loss limit
        if self.daily_pnl <= -self.daily_loss_limit * portfolio.total_value:
            return False, "Daily loss limit reached"
        
        # Check weekly loss limit
        if self.weekly_pnl <= -self.weekly_loss_limit * portfolio.total_value:
            return False, "Weekly loss limit reached"
        
        # Check maximum drawdown
        if portfolio.current_drawdown <= -self.max_drawdown_halt:
            self._halt_trading("Maximum drawdown exceeded")
            return False, "Maximum drawdown exceeded - trading halted"
        
        trade_value = position_size * current_price
        
        # Check position size limit
        if trade_value > portfolio.total_value * self.max_position_pct:
            return False, f"Exceeds max position size ({self.max_position_pct:.0%})"
        
        # Check number of positions
        if (len(portfolio.positions) >= self.max_positions and 
            signal.symbol not in portfolio.positions):
            return False, f"Maximum positions ({self.max_positions}) reached"
        
        # Check sector exposure
        sector = sector_map.get(signal.symbol, 'Unknown')
        current_sector_exposure = portfolio.get_sector_exposure(
            sector, sector_map
        )
        new_exposure = current_sector_exposure + trade_value
        if new_exposure > portfolio.total_value * self.max_sector_exposure:
            return False, f"Exceeds {sector} sector limit ({self.max_sector_exposure:.0%})"
        
        # Check correlation with existing positions
        if self._check_high_correlation(signal.symbol, portfolio):
            return False, "High correlation with existing positions"
        
        # All checks passed
        return True, "Trade approved"
    
    def _check_high_correlation(self,
                                symbol: str,
                                portfolio: 'Portfolio') -> bool:
        """
        Check if new position is highly correlated with existing.
        
        Prevents concentration risk from correlated positions.
        """
        if len(portfolio.positions) == 0:
            return False
        
        # In production, this would use historical return correlations
        # Simplified version checks sector overlap
        return False
    
    def generate_stop_orders(self,
                            symbol: str,
                            entry_price: float,
                            side: str,
                            volatility: float
                            ) -> Dict[str, float]:
        """
        Generate stop-loss and take-profit levels.
        
        Uses ATR-based stops for volatility adjustment.
        """
        # ATR-based stop (2x ATR)
        atr_stop_distance = 2 * volatility * entry_price
        
        # Percentage-based stop
        pct_stop_distance = entry_price * self.default_stop_pct
        
        # Use wider of the two
        stop_distance = max(atr_stop_distance, pct_stop_distance)
        
        if side == "BUY":
            stop_loss = entry_price - stop_distance
            take_profit = entry_price + (stop_distance * 2)  # 2:1 R/R
        else:
            stop_loss = entry_price + stop_distance
            take_profit = entry_price - (stop_distance * 2)
        
        return {
            'stop_loss': round(stop_loss, 2),
            'take_profit': round(take_profit, 2),
            'trailing_stop_pct': self.trailing_stop_pct
        }
    
    def update_daily_pnl(self, pnl: float):
        """Update daily P&L tracking"""
        self.daily_pnl = pnl
    
    def update_weekly_pnl(self, pnl: float):
        """Update weekly P&L tracking"""
        self.weekly_pnl = pnl
    
    def reset_daily(self):
        """Reset daily counters (call at market open)"""
        self.daily_pnl = 0.0
    
    def reset_weekly(self):
        """Reset weekly counters (call on Monday)"""
        self.weekly_pnl = 0.0
    
    def _halt_trading(self, reason: str):
        """Halt all trading activity"""
        self.is_halted = True
        self.halt_reason = reason
    
    def resume_trading(self):
        """Resume trading (manual intervention required)"""
        self.is_halted = False
        self.halt_reason = None
\end{lstlisting}

\section{Position Sizing Methods}

\begin{lstlisting}[caption={Position Sizing Implementations}, label={lst:position-sizing}]
class PositionSizer:
    """
    Multiple position sizing methods from quantitative 
    trading literature.
    """
    
    @staticmethod
    def fixed_fractional(portfolio_value: float,
                         risk_pct: float,
                         entry_price: float,
                         stop_price: float) -> int:
        """
        Risk a fixed percentage of portfolio per trade.
        
        This is the most common professional approach.
        
        Args:
            portfolio_value: Total portfolio value
            risk_pct: Percentage to risk (e.g., 0.02 for 2%)
            entry_price: Planned entry price
            stop_price: Stop-loss price
            
        Returns:
            Number of shares to trade
        """
        risk_per_share = abs(entry_price - stop_price)
        if risk_per_share == 0:
            return 0
        
        dollar_risk = portfolio_value * risk_pct
        shares = int(dollar_risk / risk_per_share)
        return shares
    
    @staticmethod
    def kelly_criterion(win_rate: float,
                        avg_win: float,
                        avg_loss: float) -> float:
        """
        Kelly Criterion for optimal position sizing.
        
        f* = (bp - q) / b
        
        where:
            b = avg_win / avg_loss (payoff ratio)
            p = win_rate
            q = 1 - p (loss rate)
        
        Args:
            win_rate: Historical win rate (0-1)
            avg_win: Average winning trade size
            avg_loss: Average losing trade size (positive)
            
        Returns:
            Optimal fraction of capital to risk (use half-Kelly)
        """
        if avg_loss == 0 or win_rate <= 0:
            return 0
        
        b = avg_win / avg_loss
        p = win_rate
        q = 1 - p
        
        kelly = (b * p - q) / b
        
        # Use half-Kelly for safety (reduces volatility)
        half_kelly = max(0, kelly * 0.5)
        
        # Cap at 25% maximum
        return min(half_kelly, 0.25)
    
    @staticmethod
    def volatility_parity(portfolio_value: float,
                          target_portfolio_vol: float,
                          asset_volatility: float,
                          current_price: float,
                          num_positions: int) -> int:
        """
        Equal volatility contribution from each position.
        
        Each position contributes equally to portfolio volatility.
        
        Args:
            portfolio_value: Total portfolio value
            target_portfolio_vol: Target annual volatility (e.g., 0.10)
            asset_volatility: Asset's annualized volatility
            current_price: Current asset price
            num_positions: Expected number of positions
        """
        if asset_volatility == 0 or num_positions == 0:
            return 0
        
        # Target volatility per position
        vol_per_position = target_portfolio_vol / np.sqrt(num_positions)
        
        # Dollar allocation to achieve target vol
        allocation = (portfolio_value * vol_per_position) / asset_volatility
        
        shares = int(allocation / current_price)
        return shares
    
    @staticmethod
    def equal_weight(portfolio_value: float,
                     current_price: float,
                     num_positions: int) -> int:
        """
        Simple equal-weight allocation.
        
        Each position gets equal dollar allocation.
        """
        if num_positions == 0:
            return 0
        
        allocation = portfolio_value / num_positions
        shares = int(allocation / current_price)
        return shares
\end{lstlisting}

% ============================================================================
% CHAPTER 8: MACHINE LEARNING PIPELINE
% ============================================================================

\chapter{Machine Learning Pipeline}
\label{ch:ml-pipeline}

\section{ML for Trading Overview}

Machine learning offers powerful tools for pattern recognition and prediction, but requires careful implementation to avoid common pitfalls. This chapter draws from Stefan Jansen's \textit{Machine Learning for Algorithmic Trading} and Marcos López de Prado's \textit{Advances in Financial Machine Learning}.

\begin{warningbox}
\textbf{ML Pitfalls in Finance:}
\begin{itemize}[nosep]
    \item Standard cross-validation causes data leakage
    \item Financial data has low signal-to-noise ratio
    \item Overfitting is extremely easy with many features
    \item Transaction costs can eliminate predicted alpha
\end{itemize}
\end{warningbox}

\section{Feature Engineering for ML}

\begin{lstlisting}[caption={ML Feature Engineering Pipeline}, label={lst:ml-features}]
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from typing import Tuple, List

class MLFeaturePipeline:
    """
    Machine learning feature engineering pipeline.
    
    Implements best practices from 'Machine Learning for 
    Algorithmic Trading' by Stefan Jansen.
    """
    
    def __init__(self):
        self.scaler = StandardScaler()
        self.feature_columns: List[str] = []
    
    def create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Comprehensive feature engineering for ML models.
        
        Categories:
        1. Return features
        2. Volatility features
        3. Technical indicators
        4. Volume features
        5. Relative features
        """
        features = df.copy()
        
        # ========== Return Features ==========
        for period in [1, 5, 10, 20, 60]:
            features[f'return_{period}d'] = (
                features['close'].pct_change(period)
            )
            features[f'log_return_{period}d'] = (
                np.log(features['close'] / features['close'].shift(period))
            )
        
        # ========== Volatility Features ==========
        for period in [10, 20, 60]:
            features[f'volatility_{period}d'] = (
                features['return_1d'].rolling(period).std()
            )
            features[f'volatility_ratio_{period}d'] = (
                features[f'volatility_{period}d'] / 
                features[f'volatility_{period}d'].shift(period)
            )
        
        # Parkinson volatility (using high-low)
        features['parkinson_vol'] = np.sqrt(
            (1 / (4 * np.log(2))) * 
            (np.log(features['high'] / features['low']) ** 2)
        ).rolling(20).mean()
        
        # ========== Technical Indicators ==========
        # RSI
        features['rsi_14'] = self._calculate_rsi(features['close'], 14)
        features['rsi_divergence'] = (
            features['rsi_14'] - features['rsi_14'].shift(5)
        )
        
        # MACD
        ema12 = features['close'].ewm(span=12).mean()
        ema26 = features['close'].ewm(span=26).mean()
        features['macd'] = ema12 - ema26
        features['macd_signal'] = features['macd'].ewm(span=9).mean()
        features['macd_hist'] = features['macd'] - features['macd_signal']
        
        # Moving average features
        for period in [10, 20, 50, 200]:
            ma = features['close'].rolling(period).mean()
            features[f'ma_ratio_{period}'] = features['close'] / ma
            features[f'ma_slope_{period}'] = ma.pct_change(5)
        
        # Bollinger Band position
        bb_middle = features['close'].rolling(20).mean()
        bb_std = features['close'].rolling(20).std()
        features['bb_position'] = (
            (features['close'] - bb_middle) / (2 * bb_std)
        )
        
        # ========== Volume Features ==========
        features['volume_ma_ratio'] = (
            features['volume'] / features['volume'].rolling(20).mean()
        )
        features['dollar_volume'] = features['close'] * features['volume']
        features['dollar_volume_ma'] = (
            features['dollar_volume'].rolling(20).mean()
        )
        
        # On-balance volume trend
        obv = (np.sign(features['close'].diff()) * features['volume']).cumsum()
        features['obv_slope'] = obv.pct_change(10)
        
        # ========== Price Pattern Features ==========
        features['high_low_range'] = (
            (features['high'] - features['low']) / features['close']
        )
        features['close_position'] = (
            (features['close'] - features['low']) / 
            (features['high'] - features['low'])
        )
        
        # Gap features
        features['overnight_gap'] = (
            features['open'] / features['close'].shift(1) - 1
        )
        
        # ========== Relative Features ==========
        # These would use market/sector data in production
        features['relative_strength'] = (
            features['return_20d'] - features['return_20d'].rolling(60).mean()
        )
        
        # Store feature columns (excluding target and identifiers)
        exclude = ['symbol', 'timestamp', 'open', 'high', 'low', 
                   'close', 'volume', 'adjusted_close']
        self.feature_columns = [
            col for col in features.columns if col not in exclude
        ]
        
        return features.dropna()
    
    def _calculate_rsi(self, prices: pd.Series, period: int) -> pd.Series:
        """Calculate RSI indicator"""
        delta = prices.diff()
        gain = delta.where(delta > 0, 0).rolling(period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(period).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs))
    
    def create_labels(self,
                      df: pd.DataFrame,
                      method: str = 'triple_barrier',
                      **kwargs) -> pd.Series:
        """
        Create labels for supervised learning.
        
        Methods:
        - 'binary': Simple up/down classification
        - 'triple_barrier': Lopez de Prado's method
        - 'fixed_horizon': Return over fixed period
        """
        if method == 'binary':
            return self._binary_labels(df, kwargs.get('horizon', 5))
        elif method == 'triple_barrier':
            return self._triple_barrier_labels(
                df,
                kwargs.get('horizon', 10),
                kwargs.get('upper', 0.02),
                kwargs.get('lower', 0.02)
            )
        elif method == 'fixed_horizon':
            return self._fixed_horizon_labels(
                df,
                kwargs.get('horizon', 5),
                kwargs.get('threshold', 0.01)
            )
        else:
            raise ValueError(f"Unknown labeling method: {method}")
    
    def _triple_barrier_labels(self,
                               df: pd.DataFrame,
                               horizon: int,
                               upper_barrier: float,
                               lower_barrier: float) -> pd.Series:
        """
        Triple-barrier labeling from Lopez de Prado.
        
        Labels based on which barrier is touched first:
        - Upper barrier (take profit): +1
        - Lower barrier (stop loss): -1
        - Vertical barrier (time): sign of return
        """
        labels = pd.Series(index=df.index, dtype=float)
        prices = df['close'].values
        
        for i in range(len(df) - horizon):
            entry_price = prices[i]
            upper = entry_price * (1 + upper_barrier)
            lower = entry_price * (1 - lower_barrier)
            
            # Check each future bar
            for j in range(1, horizon + 1):
                if i + j >= len(prices):
                    break
                
                future_price = prices[i + j]
                
                if future_price >= upper:
                    labels.iloc[i] = 1
                    break
                elif future_price <= lower:
                    labels.iloc[i] = -1
                    break
                elif j == horizon:
                    # Vertical barrier hit
                    ret = (future_price - entry_price) / entry_price
                    labels.iloc[i] = np.sign(ret)
        
        return labels
    
    def fit_transform(self, X: pd.DataFrame) -> np.ndarray:
        """Fit scaler and transform features"""
        return self.scaler.fit_transform(X[self.feature_columns])
    
    def transform(self, X: pd.DataFrame) -> np.ndarray:
        """Transform features using fitted scaler"""
        return self.scaler.transform(X[self.feature_columns])
\end{lstlisting}

\section{Purged Cross-Validation}

Standard cross-validation causes data leakage in time series. Purged K-Fold addresses this.

\begin{lstlisting}[caption={Purged K-Fold Cross-Validation}, label={lst:purged-cv}]
class PurgedKFold:
    """
    Purged K-Fold cross-validation for time series.
    
    From 'Advances in Financial Machine Learning' by 
    Marcos Lopez de Prado.
    
    Key features:
    1. Purging: Remove training samples overlapping with test
    2. Embargo: Add buffer after test period
    """
    
    def __init__(self,
                 n_splits: int = 5,
                 embargo_pct: float = 0.01,
                 purge_pct: float = 0.01):
        """
        Args:
            n_splits: Number of folds
            embargo_pct: Fraction of data to embargo after test
            purge_pct: Fraction to purge before test
        """
        self.n_splits = n_splits
        self.embargo_pct = embargo_pct
        self.purge_pct = purge_pct
    
    def split(self,
              X: pd.DataFrame,
              y: pd.Series = None,
              groups = None):
        """
        Generate train/test indices with purging and embargo.
        
        Yields:
            Tuple of (train_indices, test_indices)
        """
        n_samples = len(X)
        indices = np.arange(n_samples)
        
        fold_size = n_samples // self.n_splits
        embargo_size = int(n_samples * self.embargo_pct)
        purge_size = int(n_samples * self.purge_pct)
        
        for fold in range(self.n_splits):
            # Test set boundaries
            test_start = fold * fold_size
            test_end = (fold + 1) * fold_size
            
            if fold == self.n_splits - 1:
                test_end = n_samples
            
            # Purge: remove samples just before test
            purge_start = max(0, test_start - purge_size)
            
            # Embargo: skip samples just after test
            embargo_end = min(n_samples, test_end + embargo_size)
            
            # Training indices (everything except purge + test + embargo)
            train_indices = np.concatenate([
                indices[:purge_start],
                indices[embargo_end:]
            ])
            
            # Test indices
            test_indices = indices[test_start:test_end]
            
            yield train_indices, test_indices
    
    def get_n_splits(self, X=None, y=None, groups=None) -> int:
        return self.n_splits


class CombinatorialPurgedCV:
    """
    Combinatorial Purged Cross-Validation (CPCV).
    
    Generates all possible train/test combinations while
    maintaining temporal order and applying purging.
    """
    
    def __init__(self,
                 n_splits: int = 6,
                 n_test_splits: int = 2,
                 embargo_pct: float = 0.01):
        self.n_splits = n_splits
        self.n_test_splits = n_test_splits
        self.embargo_pct = embargo_pct
    
    def split(self, X: pd.DataFrame):
        """Generate CPCV train/test splits"""
        from itertools import combinations
        
        n_samples = len(X)
        indices = np.arange(n_samples)
        fold_size = n_samples // self.n_splits
        embargo_size = int(n_samples * self.embargo_pct)
        
        # Create fold boundaries
        folds = []
        for i in range(self.n_splits):
            start = i * fold_size
            end = (i + 1) * fold_size if i < self.n_splits - 1 else n_samples
            folds.append((start, end))
        
        # Generate all test combinations
        for test_fold_indices in combinations(range(self.n_splits), self.n_test_splits):
            test_indices = []
            train_indices = []
            
            for fold_idx, (start, end) in enumerate(folds):
                if fold_idx in test_fold_indices:
                    test_indices.extend(indices[start:end])
                else:
                    # Apply embargo around test folds
                    fold_train = indices[start:end]
                    
                    # Check proximity to test folds
                    for test_idx in test_fold_indices:
                        test_start, test_end = folds[test_idx]
                        
                        if fold_idx == test_idx - 1:
                            # Just before test - apply embargo
                            fold_train = fold_train[:-embargo_size]
                        elif fold_idx == test_idx + 1:
                            # Just after test - apply embargo
                            fold_train = fold_train[embargo_size:]
                    
                    train_indices.extend(fold_train)
            
            yield np.array(train_indices), np.array(test_indices)
\end{lstlisting}

\section{Model Training and Evaluation}

\begin{lstlisting}[caption={ML Model Training Pipeline}, label={lst:ml-training}]
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import warnings
warnings.filterwarnings('ignore')

class MLTradingModel:
    """
    Machine learning model for trading signal generation.
    """
    
    def __init__(self, model_type: str = 'random_forest'):
        self.model_type = model_type
        self.model = None
        self.feature_importance: pd.Series = None
        
    def _create_model(self):
        """Create the underlying ML model"""
        if self.model_type == 'random_forest':
            return RandomForestClassifier(
                n_estimators=100,
                max_depth=5,
                min_samples_leaf=50,
                min_samples_split=100,
                class_weight='balanced',
                n_jobs=-1,
                random_state=42
            )
        elif self.model_type == 'gradient_boost':
            return GradientBoostingClassifier(
                n_estimators=100,
                max_depth=3,
                learning_rate=0.1,
                min_samples_leaf=50,
                subsample=0.8,
                random_state=42
            )
        else:
            raise ValueError(f"Unknown model type: {self.model_type}")
    
    def train_with_cv(self,
                      X: pd.DataFrame,
                      y: pd.Series,
                      feature_columns: List[str]) -> Dict:
        """
        Train model with purged cross-validation.
        
        Returns:
            Dictionary with CV results and metrics
        """
        self.model = self._create_model()
        cv = PurgedKFold(n_splits=5, embargo_pct=0.01)
        
        results = {
            'accuracy': [],
            'precision': [],
            'recall': [],
            'f1': [],
            'feature_importance': []
        }
        
        X_features = X[feature_columns].values
        y_values = y.values
        
        for fold, (train_idx, test_idx) in enumerate(cv.split(X)):
            X_train = X_features[train_idx]
            y_train = y_values[train_idx]
            X_test = X_features[test_idx]
            y_test = y_values[test_idx]
            
            # Remove NaN samples
            train_mask = ~(np.isnan(X_train).any(axis=1) | np.isnan(y_train))
            test_mask = ~(np.isnan(X_test).any(axis=1) | np.isnan(y_test))
            
            X_train = X_train[train_mask]
            y_train = y_train[train_mask]
            X_test = X_test[test_mask]
            y_test = y_test[test_mask]
            
            if len(X_train) < 100 or len(X_test) < 20:
                continue
            
            # Train
            self.model.fit(X_train, y_train)
            
            # Predict
            y_pred = self.model.predict(X_test)
            
            # Metrics
            results['accuracy'].append(accuracy_score(y_test, y_pred))
            results['precision'].append(
                precision_score(y_test, y_pred, average='weighted', zero_division=0)
            )
            results['recall'].append(
                recall_score(y_test, y_pred, average='weighted', zero_division=0)
            )
            results['f1'].append(
                f1_score(y_test, y_pred, average='weighted', zero_division=0)
            )
            
            # Feature importance
            if hasattr(self.model, 'feature_importances_'):
                results['feature_importance'].append(
                    self.model.feature_importances_
                )
        
        # Aggregate results
        summary = {
            'mean_accuracy': np.mean(results['accuracy']),
            'std_accuracy': np.std(results['accuracy']),
            'mean_precision': np.mean(results['precision']),
            'mean_recall': np.mean(results['recall']),
            'mean_f1': np.mean(results['f1']),
        }
        
        # Average feature importance
        if results['feature_importance']:
            avg_importance = np.mean(results['feature_importance'], axis=0)
            self.feature_importance = pd.Series(
                avg_importance, 
                index=feature_columns
            ).sort_values(ascending=False)
            summary['top_features'] = self.feature_importance.head(10).to_dict()
        
        # Final training on all data
        full_mask = ~(np.isnan(X_features).any(axis=1) | np.isnan(y_values))
        self.model.fit(X_features[full_mask], y_values[full_mask])
        
        return summary
    
    def predict(self, X: pd.DataFrame, feature_columns: List[str]) -> np.ndarray:
        """Generate predictions"""
        return self.model.predict(X[feature_columns].values)
    
    def predict_proba(self, X: pd.DataFrame, feature_columns: List[str]) -> np.ndarray:
        """Generate prediction probabilities"""
        return self.model.predict_proba(X[feature_columns].values)
\end{lstlisting}

% ============================================================================
% CHAPTER 9: LIVE TRADING EXECUTION
% ============================================================================

\chapter{Live Trading Execution}
\label{ch:live-trading}

\section{Broker Integration}

The system supports multiple brokers through a common interface. This section demonstrates Alpaca Markets integration.

\begin{lstlisting}[caption={Broker Interface and Alpaca Implementation}, label={lst:broker}]
from abc import ABC, abstractmethod
from typing import Dict, List, Optional
import alpaca_trade_api as tradeapi

class BrokerInterface(ABC):
    """Abstract interface for broker connections"""
    
    @abstractmethod
    def connect(self) -> bool:
        """Establish connection to broker"""
        pass
    
    @abstractmethod
    def submit_order(self, order: 'Order') -> str:
        """Submit order, return order ID"""
        pass
    
    @abstractmethod
    def cancel_order(self, order_id: str) -> bool:
        """Cancel an open order"""
        pass
    
    @abstractmethod
    def get_order_status(self, order_id: str) -> Dict:
        """Get current order status"""
        pass
    
    @abstractmethod
    def get_position(self, symbol: str) -> Optional[Dict]:
        """Get current position for symbol"""
        pass
    
    @abstractmethod
    def get_account(self) -> Dict:
        """Get account information"""
        pass
    
    @abstractmethod
    def get_positions(self) -> List[Dict]:
        """Get all current positions"""
        pass


class AlpacaBroker(BrokerInterface):
    """
    Alpaca Markets API integration.
    
    Supports both paper and live trading.
    """
    
    def __init__(self,
                 api_key: str,
                 secret_key: str,
                 paper: bool = True):
        """
        Initialize Alpaca connection.
        
        Args:
            api_key: Alpaca API key
            secret_key: Alpaca secret key
            paper: Use paper trading if True
        """
        base_url = ('https://paper-api.alpaca.markets' 
                   if paper 
                   else 'https://api.alpaca.markets')
        
        self.api = tradeapi.REST(
            api_key, 
            secret_key, 
            base_url,
            api_version='v2'
        )
        self.paper = paper
    
    def connect(self) -> bool:
        """Verify connection by fetching account"""
        try:
            account = self.api.get_account()
            return account.status == 'ACTIVE'
        except Exception as e:
            print(f"Connection failed: {e}")
            return False
    
    def submit_order(self, order: 'Order') -> str:
        """Submit order to Alpaca"""
        try:
            alpaca_order = self.api.submit_order(
                symbol=order.symbol,
                qty=order.quantity,
                side=order.side.lower(),
                type=order.order_type.lower(),
                time_in_force='day',
                limit_price=order.limit_price if order.order_type == 'LIMIT' else None,
                stop_price=order.stop_price if 'STOP' in order.order_type else None,
                client_order_id=order.client_id
            )
            return alpaca_order.id
        except Exception as e:
            raise OrderExecutionError(f"Order submission failed: {e}")
    
    def cancel_order(self, order_id: str) -> bool:
        """Cancel an open order"""
        try:
            self.api.cancel_order(order_id)
            return True
        except Exception as e:
            print(f"Cancel failed: {e}")
            return False
    
    def get_order_status(self, order_id: str) -> Dict:
        """Get order status"""
        order = self.api.get_order(order_id)
        return {
            'id': order.id,
            'status': order.status,
            'filled_qty': int(order.filled_qty or 0),
            'filled_avg_price': float(order.filled_avg_price or 0),
            'created_at': order.created_at,
            'updated_at': order.updated_at
        }
    
    def get_position(self, symbol: str) -> Optional[Dict]:
        """Get position for a symbol"""
        try:
            pos = self.api.get_position(symbol)
            return {
                'symbol': pos.symbol,
                'qty': int(pos.qty),
                'side': 'long' if int(pos.qty) > 0 else 'short',
                'avg_entry_price': float(pos.avg_entry_price),
                'market_value': float(pos.market_value),
                'cost_basis': float(pos.cost_basis),
                'unrealized_pl': float(pos.unrealized_pl),
                'unrealized_plpc': float(pos.unrealized_plpc),
                'current_price': float(pos.current_price)
            }
        except Exception:
            return None
    
    def get_positions(self) -> List[Dict]:
        """Get all positions"""
        positions = self.api.list_positions()
        return [
            {
                'symbol': pos.symbol,
                'qty': int(pos.qty),
                'market_value': float(pos.market_value),
                'unrealized_pl': float(pos.unrealized_pl)
            }
            for pos in positions
        ]
    
    def get_account(self) -> Dict:
        """Get account information"""
        account = self.api.get_account()
        return {
            'equity': float(account.equity),
            'cash': float(account.cash),
            'buying_power': float(account.buying_power),
            'portfolio_value': float(account.portfolio_value),
            'day_trade_count': int(account.daytrade_count),
            'pattern_day_trader': account.pattern_day_trader
        }
\end{lstlisting}

\section{Trading Engine}

\begin{lstlisting}[caption={Main Trading Engine}, label={lst:trading-engine}]
import asyncio
import logging
from datetime import datetime, time
from typing import List

class TradingEngine:
    """
    Main trading engine orchestrating all components.
    
    Runs the main event loop for live trading.
    """
    
    def __init__(self,
                 strategies: List[BaseStrategy],
                 broker: BrokerInterface,
                 risk_manager: RiskManager,
                 data_feed: 'DataFeed',
                 config: Dict):
        """
        Initialize trading engine.
        
        Args:
            strategies: List of active strategies
            broker: Broker connection
            risk_manager: Risk management instance
            data_feed: Market data feed
            config: Engine configuration
        """
        self.strategies = strategies
        self.broker = broker
        self.risk_manager = risk_manager
        self.data_feed = data_feed
        self.config = config
        
        self.is_running = False
        self.portfolio = Portfolio()
        self.pending_orders: Dict[str, 'Order'] = {}
        
        self.logger = logging.getLogger('TradingEngine')
        self._setup_logging()
    
    def _setup_logging(self):
        """Configure logging"""
        handler = logging.FileHandler('trading.log')
        handler.setFormatter(logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        ))
        self.logger.addHandler(handler)
        self.logger.setLevel(logging.INFO)
    
    async def run(self):
        """Main trading loop"""
        self.is_running = True
        self.logger.info("Trading engine started")
        
        # Connect to broker
        if not self.broker.connect():
            self.logger.error("Failed to connect to broker")
            return
        
        # Initialize portfolio from broker
        await self._sync_portfolio()
        
        while self.is_running:
            try:
                # Check market hours
                if not self._is_market_open():
                    await asyncio.sleep(60)
                    continue
                
                # Get latest market data
                market_data = await self.data_feed.get_latest()
                
                # Generate signals from all strategies
                all_signals = []
                for strategy in self.strategies:
                    if strategy.is_active:
                        signals = strategy.generate_signals(market_data)
                        all_signals.extend(signals)
                
                # Prioritize and filter signals
                signals = self._prioritize_signals(all_signals)
                
                # Process each signal
                for signal in signals:
                    await self._process_signal(signal, market_data)
                
                # Manage existing positions
                await self._manage_positions(market_data)
                
                # Update risk manager
                self._update_risk_tracking()
                
                # Log status
                if datetime.now().minute % 15 == 0:
                    self._log_status()
                
                await asyncio.sleep(self.config.get('tick_interval', 1))
                
            except Exception as e:
                self.logger.error(f"Error in trading loop: {e}")
                await asyncio.sleep(5)
    
    async def _process_signal(self,
                              signal: Signal,
                              market_data: pd.DataFrame):
        """Process a single trading signal"""
        
        # Get current price
        symbol_data = market_data[market_data['symbol'] == signal.symbol]
        if symbol_data.empty:
            return
        
        current_price = symbol_data['close'].iloc[-1]
        
        # Calculate volatility for position sizing
        volatility = self._calculate_volatility(signal.symbol, market_data)
        
        # Get account value
        account = self.broker.get_account()
        portfolio_value = account['portfolio_value']
        
        # Calculate position size
        position_size = self.risk_manager.calculate_position_size(
            signal=signal,
            portfolio_value=portfolio_value,
            current_price=current_price,
            volatility=volatility
        )
        
        if position_size == 0:
            return
        
        # Risk check
        allowed, reason = self.risk_manager.check_trade_allowed(
            signal=signal,
            portfolio=self.portfolio,
            position_size=position_size,
            current_price=current_price,
            sector_map=self.config.get('sector_map', {})
        )
        
        if not allowed:
            self.logger.warning(f"Trade rejected for {signal.symbol}: {reason}")
            return
        
        # Create order
        order = Order(
            symbol=signal.symbol,
            side='BUY' if signal.signal_type == SignalType.BUY else 'SELL',
            quantity=position_size,
            order_type='LIMIT',
            limit_price=self._calculate_limit_price(current_price, signal)
        )
        
        # Submit order
        try:
            order_id = self.broker.submit_order(order)
            self.pending_orders[order_id] = order
            self.logger.info(
                f"Order submitted: {order_id} - {signal.symbol} "
                f"{order.side} {position_size} @ {order.limit_price}"
            )
        except Exception as e:
            self.logger.error(f"Order submission failed: {e}")
    
    def _is_market_open(self) -> bool:
        """Check if market is currently open"""
        now = datetime.now()
        
        # Skip weekends
        if now.weekday() >= 5:
            return False
        
        # Check market hours (9:30 AM - 4:00 PM ET)
        market_open = time(9, 30)
        market_close = time(16, 0)
        
        return market_open <= now.time() <= market_close
    
    def _prioritize_signals(self, signals: List[Signal]) -> List[Signal]:
        """
        Prioritize and deduplicate signals.
        
        Higher strength signals get priority. Only one signal
        per symbol is allowed.
        """
        # Sort by strength descending
        sorted_signals = sorted(signals, key=lambda s: s.strength, reverse=True)
        
        # Deduplicate by symbol
        seen_symbols = set()
        unique_signals = []
        
        for signal in sorted_signals:
            if signal.symbol not in seen_symbols:
                unique_signals.append(signal)
                seen_symbols.add(signal.symbol)
        
        return unique_signals
    
    def stop(self):
        """Stop the trading engine"""
        self.is_running = False
        self.logger.info("Trading engine stopped")
\end{lstlisting}

% ============================================================================
% CHAPTER 10: MONITORING AND ANALYTICS
% ============================================================================

\chapter{Monitoring and Analytics}
\label{ch:monitoring}

\section{Performance Metrics}

\begin{table}[htbp]
    \centering
    \caption{Key Performance Indicators (KPIs)}
    \label{tab:kpis}
    \begin{tabularx}{\textwidth}{@{}l l X@{}}
        \toprule
        \textbf{Metric} & \textbf{Formula} & \textbf{Interpretation} \\
        \midrule
        Sharpe Ratio & $\frac{R_p - R_f}{\sigma_p}$ & Risk-adjusted return; $>1$ is good, $>2$ is excellent \\[0.5em]
        Sortino Ratio & $\frac{R_p - R_f}{\sigma_d}$ & Like Sharpe but only penalizes downside volatility \\[0.5em]
        Max Drawdown & $\max\left(\frac{P_{peak} - P_{trough}}{P_{peak}}\right)$ & Largest peak-to-trough decline \\[0.5em]
        Calmar Ratio & $\frac{R_{annual}}{|MaxDD|}$ & Return per unit of drawdown risk \\[0.5em]
        Win Rate & $\frac{N_{wins}}{N_{total}}$ & Percentage of profitable trades \\[0.5em]
        Profit Factor & $\frac{\sum{wins}}{\sum{losses}}$ & Ratio of gross profit to gross loss; $>1.5$ is good \\[0.5em]
        \bottomrule
    \end{tabularx}
\end{table}

\section{Alerting System}

\begin{lstlisting}[caption={Alert Manager Implementation}, label={lst:alerts}]
from dataclasses import dataclass
from typing import Callable, List
from enum import Enum

class AlertSeverity(Enum):
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"

@dataclass
class AlertRule:
    """Definition of an alert rule"""
    name: str
    condition: Callable[['Portfolio', pd.DataFrame], bool]
    severity: AlertSeverity
    message_template: str
    cooldown_minutes: int = 30

class AlertManager:
    """
    Real-time alerting system for trading operations.
    """
    
    def __init__(self, notification_channels: List[str]):
        """
        Args:
            notification_channels: List of channels ('email', 'slack', 'sms')
        """
        self.channels = notification_channels
        self.rules: List[AlertRule] = []
        self.last_triggered: Dict[str, datetime] = {}
        self._setup_default_rules()
    
    def _setup_default_rules(self):
        """Configure default alert rules"""
        
        # Drawdown alert
        self.add_rule(AlertRule(
            name="drawdown_warning",
            condition=lambda p, d: p.current_drawdown < -0.05,
            severity=AlertSeverity.WARNING,
            message_template="Portfolio drawdown at {drawdown:.2%}",
            cooldown_minutes=60
        ))
        
        # Critical drawdown
        self.add_rule(AlertRule(
            name="drawdown_critical",
            condition=lambda p, d: p.current_drawdown < -0.10,
            severity=AlertSeverity.CRITICAL,
            message_template="CRITICAL: Drawdown at {drawdown:.2%}. Consider halting.",
            cooldown_minutes=30
        ))
        
        # Daily loss limit
        self.add_rule(AlertRule(
            name="daily_loss",
            condition=lambda p, d: p.daily_pnl < -p.total_value * 0.02,
            severity=AlertSeverity.WARNING,
            message_template="Daily loss exceeds 2%: {daily_pnl:.2%}",
            cooldown_minutes=60
        ))
        
        # High volatility
        self.add_rule(AlertRule(
            name="volatility_spike",
            condition=self._check_volatility_spike,
            severity=AlertSeverity.INFO,
            message_template="Market volatility spike detected",
            cooldown_minutes=120
        ))
    
    def _check_volatility_spike(self, 
                                portfolio: 'Portfolio',
                                market_data: pd.DataFrame) -> bool:
        """Check for unusual market volatility"""
        if 'VIX' in market_data['symbol'].values:
            vix = market_data[market_data['symbol'] == 'VIX']['close'].iloc[-1]
            return vix > 25
        return False
    
    def add_rule(self, rule: AlertRule):
        """Add a new alert rule"""
        self.rules.append(rule)
    
    def check_alerts(self,
                     portfolio: 'Portfolio',
                     market_data: pd.DataFrame):
        """Check all alert conditions"""
        
        for rule in self.rules:
            # Check cooldown
            if rule.name in self.last_triggered:
                elapsed = datetime.now() - self.last_triggered[rule.name]
                if elapsed.total_seconds() < rule.cooldown_minutes * 60:
                    continue
            
            # Evaluate condition
            if rule.condition(portfolio, market_data):
                self._trigger_alert(rule, portfolio)
    
    def _trigger_alert(self, rule: AlertRule, portfolio: 'Portfolio'):
        """Trigger an alert"""
        message = rule.message_template.format(
            drawdown=portfolio.current_drawdown,
            daily_pnl=portfolio.daily_pnl / portfolio.total_value,
            equity=portfolio.total_value
        )
        
        full_message = f"[{rule.severity.value.upper()}] {rule.name}: {message}"
        
        for channel in self.channels:
            self._send_notification(channel, full_message, rule.severity)
        
        self.last_triggered[rule.name] = datetime.now()
    
    def _send_notification(self,
                          channel: str,
                          message: str,
                          severity: AlertSeverity):
        """Send notification through specified channel"""
        if channel == 'slack':
            self._send_slack(message, severity)
        elif channel == 'email':
            self._send_email(message, severity)
        elif channel == 'sms':
            self._send_sms(message, severity)
    
    def _send_slack(self, message: str, severity: AlertSeverity):
        """Send Slack notification"""
        # Implementation would use Slack webhook
        pass
    
    def _send_email(self, message: str, severity: AlertSeverity):
        """Send email notification"""
        # Implementation would use SMTP or email service
        pass
    
    def _send_sms(self, message: str, severity: AlertSeverity):
        """Send SMS notification"""
        # Implementation would use Twilio or similar
        pass
\end{lstlisting}

% ============================================================================
% CHAPTER 11: DEPLOYMENT
% ============================================================================

\chapter{Deployment Architecture}
\label{ch:deployment}

\section{Containerized Deployment}

The system is designed for containerized deployment using Docker and Kubernetes.

\begin{lstlisting}[style=yamlstyle, caption={Docker Compose Configuration}, label={lst:docker-compose}]
version: '3.8'

services:
  trading-engine:
    build:
      context: .
      dockerfile: Dockerfile.trading
    environment:
      - ALPACA_API_KEY=${ALPACA_API_KEY}
      - ALPACA_SECRET_KEY=${ALPACA_SECRET_KEY}
      - DATABASE_URL=postgresql://postgres:password@timescaledb:5432/trading
      - REDIS_URL=redis://redis:6379
    depends_on:
      - timescaledb
      - redis
    restart: unless-stopped
    volumes:
      - ./logs:/app/logs
    
  backtester:
    build:
      context: .
      dockerfile: Dockerfile.backtester
    environment:
      - DATABASE_URL=postgresql://postgres:password@timescaledb:5432/trading
    volumes:
      - ./strategies:/app/strategies
      - ./data:/app/data
      
  data-collector:
    build:
      context: .
      dockerfile: Dockerfile.collector
    environment:
      - POLYGON_API_KEY=${POLYGON_API_KEY}
      - DATABASE_URL=postgresql://postgres:password@timescaledb:5432/trading
    depends_on:
      - timescaledb
    restart: unless-stopped
    
  dashboard:
    build:
      context: ./dashboard
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - API_URL=http://trading-engine:8000
      
  timescaledb:
    image: timescale/timescaledb:latest-pg14
    environment:
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=trading
    volumes:
      - timescale-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
      
  redis:
    image: redis:7-alpine
    volumes:
      - redis-data:/data
    ports:
      - "6379:6379"
      
  prometheus:
    image: prom/prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
      
  grafana:
    image: grafana/grafana
    ports:
      - "3001:3000"
    volumes:
      - grafana-data:/var/lib/grafana

volumes:
  timescale-data:
  redis-data:
  grafana-data:
\end{lstlisting}

\section{CI/CD Pipeline}

\begin{lstlisting}[style=yamlstyle, caption={GitHub Actions CI/CD Pipeline}, label={lst:github-actions}]
name: Trading System CI/CD

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov
          
      - name: Run unit tests
        run: pytest tests/unit --cov=src --cov-report=xml
        
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        
  backtest-validation:
    runs-on: ubuntu-latest
    needs: test
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: Install dependencies
        run: pip install -r requirements.txt
        
      - name: Run strategy validation
        run: python scripts/validate_strategies.py --min-sharpe 0.5
        
      - name: Archive results
        uses: actions/upload-artifact@v3
        with:
          name: backtest-results
          path: results/
          
  deploy-staging:
    runs-on: ubuntu-latest
    needs: [test, backtest-validation]
    if: github.ref == 'refs/heads/develop'
    steps:
      - uses: actions/checkout@v4
      
      - name: Deploy to staging
        run: |
          kubectl config set-cluster staging
          kubectl apply -f k8s/staging/
          
  deploy-production:
    runs-on: ubuntu-latest
    needs: [test, backtest-validation]
    if: github.ref == 'refs/heads/main'
    environment: production
    steps:
      - uses: actions/checkout@v4
      
      - name: Deploy to production
        run: |
          kubectl config set-cluster production
          kubectl apply -f k8s/production/
\end{lstlisting}

% ============================================================================
% CHAPTER 12: DEVELOPMENT ROADMAP
% ============================================================================

\chapter{Development Roadmap}
\label{ch:roadmap}

\section{Implementation Timeline}

\begin{table}[htbp]
    \centering
    \caption{Development Phases and Milestones}
    \label{tab:timeline}
    \begin{tabularx}{\textwidth}{@{}l l X@{}}
        \toprule
        \textbf{Phase} & \textbf{Duration} & \textbf{Deliverables} \\
        \midrule
        Foundation & Weeks 1-2 & Project setup, data models, database schema \\
        Data Layer & Weeks 3-4 & Data connectors, feature engineering pipeline \\
        Backtesting & Weeks 5-6 & Backtester engine, performance metrics \\
        Strategies & Weeks 7-10 & Implement 3-4 base strategies (CAN SLIM, Mean Reversion, Momentum) \\
        Risk Management & Weeks 11-12 & Position sizing, risk checks, stop-losses \\
        Paper Trading & Weeks 13-14 & Broker integration, simulated execution \\
        ML Pipeline & Weeks 15-18 & Feature engineering, model training, integration \\
        Dashboard & Weeks 19-20 & Monitoring UI, alerts, reporting \\
        Live Trading & Weeks 21-24 & Production deployment, gradual capital deployment \\
        \bottomrule
    \end{tabularx}
\end{table}

\section{Success Criteria}

\begin{table}[htbp]
    \centering
    \caption{Success Criteria by Phase}
    \label{tab:success-criteria}
    \begin{tabularx}{\textwidth}{@{}l X@{}}
        \toprule
        \textbf{Criterion} & \textbf{Target} \\
        \midrule
        Backtesting Validation & Sharpe $> 1.0$ OOS, Profit Factor $> 1.5$ \\
        Risk Discipline & Max Drawdown $< 15\%$, Daily VaR $< 2\%$ \\
        Execution Quality & Slippage $< 10$ bps, Fill Rate $> 95\%$ \\
        System Reliability & Uptime $> 99.9\%$ during market hours \\
        Robustness & Positive returns in $> 70\%$ of walk-forward folds \\
        \bottomrule
    \end{tabularx}
\end{table}

\section{Risk Considerations}

\begin{warningbox}
\textbf{Key Risks to Monitor:}
\begin{enumerate}[nosep]
    \item \textbf{Overfitting}: Strategies may perform well in backtest but fail live
    \item \textbf{Regime Change}: Market conditions may invalidate strategy assumptions
    \item \textbf{Execution Risk}: Live execution differs from backtest assumptions
    \item \textbf{Technology Risk}: System failures during critical market moments
    \item \textbf{Regulatory Risk}: Changes in trading rules or requirements
\end{enumerate}
\end{warningbox}

% ============================================================================
% APPENDICES
% ============================================================================

\appendix

\chapter{Reference Materials}
\label{app:references}

\section{Recommended Reading}

\subsection{Fundamental Analysis}
\begin{itemize}
    \item Graham, Benjamin. \textit{The Intelligent Investor}
    \item Kratter, Matthew R. \textit{A Beginner's Guide to the Stock Market}
\end{itemize}

\subsection{Technical Analysis}
\begin{itemize}
    \item Murphy, John J. \textit{Technical Analysis of the Financial Markets}
    \item O'Neil, William J. \textit{How to Make Money in Stocks}
    \item Pring, Martin. \textit{Technical Analysis Explained}
\end{itemize}

\subsection{Trading Psychology}
\begin{itemize}
    \item Douglas, Mark. \textit{Trading in the Zone}
    \item Schwager, Jack D. \textit{Market Wizards}
\end{itemize}

\subsection{Quantitative and Algorithmic Trading}
\begin{itemize}
    \item Chan, Ernie. \textit{Algorithmic Trading: Winning Strategies and Their Rationale}
    \item Chan, Ernie. \textit{Quantitative Trading}
    \item Davey, Kevin J. \textit{Building Winning Algorithmic Trading Systems}
    \item Johnson, Barry. \textit{Algorithmic Trading and DMA}
\end{itemize}

\subsection{Machine Learning for Finance}
\begin{itemize}
    \item Jansen, Stefan. \textit{Machine Learning for Algorithmic Trading}
    \item López de Prado, Marcos. \textit{Advances in Financial Machine Learning}
    \item Hilpisch, Yves. \textit{Python for Finance}
\end{itemize}

\subsection{High-Frequency and Advanced Topics}
\begin{itemize}
    \item Aldridge, Irene. \textit{High-Frequency Trading: A Practical Guide}
    \item Kissell, Robert. \textit{The Science of Algorithmic Trading and Portfolio Management}
\end{itemize}

\chapter{Glossary}
\label{app:glossary}

\begin{description}[style=nextline]
    \item[Alpha] Excess return above benchmark performance
    \item[ATR] Average True Range; volatility indicator
    \item[Backtest] Historical simulation of trading strategy
    \item[Basis Point (bp)] 1/100th of 1\% (0.01\%)
    \item[Calmar Ratio] Annualized return divided by maximum drawdown
    \item[Drawdown] Peak-to-trough decline in portfolio value
    \item[Kelly Criterion] Optimal position sizing formula
    \item[MACD] Moving Average Convergence Divergence indicator
    \item[OHLCV] Open, High, Low, Close, Volume data
    \item[RSI] Relative Strength Index; momentum oscillator
    \item[Sharpe Ratio] Risk-adjusted return measure
    \item[Slippage] Difference between expected and actual execution price
    \item[Sortino Ratio] Like Sharpe but only penalizes downside volatility
    \item[TWAP] Time-Weighted Average Price execution algorithm
    \item[VaR] Value at Risk; maximum expected loss
    \item[VWAP] Volume-Weighted Average Price execution algorithm
\end{description}

% ============================================================================
% END DOCUMENT
% ============================================================================

\end{document}
