% !TEX TS-program = pdflatex
\documentclass[11pt,a4paper]{article}

% -------------------- Packages --------------------
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{inconsolata}
\usepackage{upquote}
\usepackage{microtype}
\usepackage[margin=1in]{geometry}
\usepackage{parskip}
\usepackage[hyphens]{url}
\usepackage{hyperref}
\usepackage{bookmark}
\usepackage{enumitem}
\usepackage[dvipsnames]{xcolor}
\usepackage{booktabs}
\usepackage{array}
\usepackage{ragged2e}
\usepackage[most]{tcolorbox}
\usepackage{amsmath,amssymb}
\usepackage{titlesec}
\usepackage{graphicx}
\usepackage{listings}

% -------------------- Readability Tweaks --------------------
\linespread{1.03}
\setlength{\parindent}{0pt}
\setlength{\parskip}{0.55em}
\setlength{\emergencystretch}{2em}
\renewcommand{\arraystretch}{1.12}
\raggedbottom
\clubpenalty=10000
\widowpenalty=10000
\displaywidowpenalty=10000
\titlespacing*{\section}{0pt}{0.9em}{0.35em}
\titlespacing*{\subsection}{0pt}{0.75em}{0.25em}
\setlist{leftmargin=*,itemsep=2pt,topsep=4pt}
\setlist[itemize]{itemsep=2pt}
\setlist[enumerate]{itemsep=2pt}

% -------------------- Colors --------------------
\definecolor{Primary}{HTML}{0E7490}
\definecolor{Accent}{HTML}{0EA5E9}
\definecolor{Soft}{HTML}{F1F5F9}
\definecolor{Ink}{HTML}{0F172A}
\definecolor{Meta}{HTML}{475569}
\definecolor{OK}{HTML}{16A34A}
\definecolor{Warn}{HTML}{EA580C}
\definecolor{Bad}{HTML}{DC2626}

\hypersetup{
  colorlinks=true,
  linkcolor=Primary,
  urlcolor=Primary,
  citecolor=Primary,
  breaklinks=true,
  pdfauthor={},
  pdftitle={User Story Template & Guide}
}
\urlstyle{same}
\titleformat{\section}{\large\bfseries\color{Ink}}{\thesection}{0.6em}{}
\titleformat{\subsection}{\normalsize\bfseries\color{Ink}}{\thesubsection}{0.6em}{}

\newcommand{\checkbox}{\(\square\)}
\newcommand{\checkedbox}{\(\blacksquare\)}
\newcommand{\eg}{e.g.\ }
\newcommand{\ie}{i.e.\ }

% -------------------- Gherkin (listings) --------------------
\lstdefinelanguage{Gherkin}{
  morekeywords={Feature,Background,Scenario,Scenario\ Outline,Examples,Given,When,Then,And,But},
  sensitive=true,
}
\lstset{
  language=Gherkin,
  basicstyle=\ttfamily\small,
  keywordstyle=\color{Primary}\bfseries,
  commentstyle=\itshape\color{Meta},
  showstringspaces=false,
  frame=single,
  framerule=0.4pt,
  rulecolor=\color{Soft},
  backgroundcolor=\color{Soft},
  tabsize=2,
  columns=fullflexible,
  keepspaces=true,
  breaklines=true,
  breakatwhitespace=true,
  xleftmargin=1ex,
  framexleftmargin=1ex,
  framesep=0.6ex,
  aboveskip=3pt,
  belowskip=6pt
}

% -------------------- Card Look & Feel (matches screenshot) --------------------
\tcbset{
  colback=gray!2,
  colframe=gray!50,
  colbacktitle=gray!6,
  coltitle=black,
  fonttitle=\bfseries\large,
  arc=2pt,
  boxrule=0.4pt,
  left=8pt,right=8pt,top=8pt,bottom=8pt,
  enhanced,
  breakable,
  borderline west={2pt}{0pt}{MidnightBlue}
}

% Badges/pills
\newtcbox{\pill}{on line, arc=3pt, boxsep=0.8pt, left=4pt,right=4pt,top=1pt,bottom=1pt,
  colframe=gray!50, colback=gray!15, boxrule=0.3pt}
\newcommand{\badge}[1]{\pill{\footnotesize #1}}

% Footer helpers
\newcommand{\DoR}{\textbf{Definition of Ready:} Persona clear; AC drafted; Dependencies known; Estimate set.}
\newcommand{\DoD}{\textbf{Definition of Done:} All ACs pass; Tests green; Security/a11y checks; Docs updated; Deployed/flagged.}
\let\cb\checkbox

% Widths for robust tables (no tabularx needed)
\newlength{\StoryLabelW}
\setlength{\StoryLabelW}{3.2cm}
\newlength{\StoryValueW}
\setlength{\StoryValueW}{\dimexpr\linewidth-\StoryLabelW-2\tabcolsep\relax}

% -------------------- Story Card macro (exact screenshot layout) --------------------
% 1: ID   2: Title   3: Epic/Feature   4: Business Value
% 5: Priority   6: Estimate(SP)   7: Persona   8: Dependencies   9: Assumptions/Risks
\newcommand{\StoryCard}[9]{%
  \newpage
  \begin{tcolorbox}[title={\textbf{#1}\ \textemdash\ #2}]
  \small
  \begin{tabular}{@{}>{\raggedleft\arraybackslash\bfseries}p{\StoryLabelW} >{\RaggedRight\arraybackslash}p{\StoryValueW}@{}}
    Epic / Feature          & #3 \\
    Business Value          & #4 \\
    Priority / Estimate     & \badge{Priority: #5}\ \badge{SP: #6} \\
    Persona                 & #7 \\
    Dependencies            & #8 \\
    Assumptions / Risks     & #9 \\
  \end{tabular}

  \medskip
  \textbf{Story}\quad
  \emph{As a #7, I want to #2 so that #4.}

  \medskip
  \textbf{Non-Functional}\quad
  \badge{Performance}\ \badge{Security}\ \badge{Reliability}\ \badge{Accessibility}\ \badge{Privacy}\ \badge{i18n}

  \medskip
  \textbf{Acceptance Criteria (BDD)}
  \begin{description}[leftmargin=2.4cm, labelwidth=2.3cm, style=nextline, itemsep=2pt, topsep=2pt]
    \item[\textbf{Scenario}] Happy path
    \item[\textbf{Given}] the target repository and pipeline configuration are available
    \item[\textbf{When}] the user completes the \emph{Hands-on Objective}
    \item[\textbf{Then}] the stated \emph{Outcome} is observable and recorded in the pipeline/job summary
  \end{description}

  \vspace{0.2\baselineskip}
  {\footnotesize\color{gray!60}\DoR\ \textbullet\ \DoD}
  \end{tcolorbox}
}

% -------------------- Tasks box (matches screenshot style) --------------------
\newenvironment{TasksBox}[1][Tasks]{%
  \begin{tcolorbox}[
    enhanced,breakable,
    colback=gray!1, colframe=gray!35,
    colbacktitle=gray!6, coltitle=black,
    title={#1}, fonttitle=\bfseries,
    borderline west={1.8pt}{0pt}{MidnightBlue},
    arc=2pt, boxrule=0.4pt,
    left=10pt,right=10pt,top=6pt,bottom=6pt,
    before skip=6pt, after skip=10pt
  ]
  \small
  \begin{itemize}[label=\cb, leftmargin=*, labelsep=0.6em, itemsep=4pt, topsep=2pt, parsep=0pt]
}{%
  \end{itemize}
  \end{tcolorbox}
}

% -------------------- Document --------------------
\begin{document}
\begin{center}
{\huge \textbf{Application Security Engineer User Stories}}\\[2pt]
\textcolor{Meta}{Operational user stories for an AppSec engineer running a modern secure SDLC (SAST, SCA, secrets, IaC, supply chain security, and vulnerability management)}\\[6pt]
\end{center}

\noindent\textbf{Context}\\
These stories are written from the perspective of an \textbf{AppSec engineer} responsible for enabling and operating a scalable application security program across multiple engineering teams. The backlog emphasizes: (1) \textbf{shift-left} controls (SAST, SCA, secrets, IaC and container scanning), (2) \textbf{release gating} and developer experience, (3) \textbf{vulnerability management} workflows with clear SLAs and risk acceptance, (4) \textbf{supply chain security} (SBOM, signing, provenance), and (5) \textbf{metrics and reporting} that communicate risk and progress to stakeholders.

\StoryCard{APPSEC-GOV-001}{Define and publish secure coding and review standards}{AppSec Governance}
{Create a consistent baseline for secure design, coding, and review so teams prevent recurring classes of vulnerabilities and reviewers know what to look for}
{Must}{3}
{AppSec engineer}
{Security leadership sponsorship; engineering representatives for review; documentation platform}
{Standards may be ignored without enforcement; overly prescriptive rules can slow delivery; standards must be maintained as frameworks change}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Draft secure coding standards aligned to OWASP ASVS and language-specific guidance (input validation, authn/authz, crypto, logging, error handling).
  \item \cb Define secure code review checklist and minimum requirements for security-sensitive changes.
  \item \cb Publish standards in a single source of truth and add short, searchable examples.
  \item \cb Create an exception process for legacy systems and document compensating controls.
  \item \cb Socialize standards with engineering leads and incorporate feedback into a v1 release.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: Secure coding standards are published and discoverable
  Given the organization maintains a documentation portal
  When an engineer searches for the secure coding standard for a supported language
  Then the standard is available with actionable guidance and examples
  And the document includes versioning and an owner for updates

Scenario: Secure review checklist is used in pull requests
  Given a pull request changes authentication, authorization, or data validation logic
  When the reviewer follows the secure review checklist
  Then the review identifies required controls and common pitfalls for that change type
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-GOV-002}{Establish a security severity and SLA matrix for remediation}{AppSec Governance}
{Align teams on what constitutes Critical/High/Medium/Low risk and define remediation timeframes to manage risk consistently across the portfolio}
{Must}{3}
{AppSec engineer}
{Risk management input; agreement from engineering leadership; vulnerability management platform or tracker}
{Severity inflation can cause alert fatigue; inconsistent asset criticality data can undermine prioritization}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Define severity levels by impact and exploitability, mapping to CVSS where applicable.
  \item \cb Incorporate application criticality tiers and internet-exposure into prioritization.
  \item \cb Set remediation SLAs (for example: Critical 7d, High 30d, Medium 90d, Low best-effort).
  \item \cb Document how SLA pauses work (awaiting vendor fix, accepted risk, false positive).
  \item \cb Publish the matrix and embed it into ticket templates and dashboards.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: A new vulnerability is assigned an SLA automatically
  Given a vulnerability is created with severity and affected asset criticality
  When the vulnerability is recorded in the tracking system
  Then a remediation due date is set based on the severity and criticality matrix
  And the due date is visible to the remediation owner

Scenario: SLA pause is tracked for accepted risk
  Given a vulnerability cannot be remediated within the SLA
  When the owner submits a risk acceptance request and it is approved
  Then the SLA is paused or closed with an accepted risk status
  And the approval record is linked to the vulnerability ticket
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-TM-001}{Run threat modeling for new high-risk features and services}{Secure Design and Threat Modeling}
{Identify architectural security risks early and drive design mitigations before code is written, reducing downstream findings and rework}
{Must}{5}
{AppSec engineer}
{Architecture review cadence; feature owners; threat modeling framework and templates}
{Insufficient participation reduces value; designs may change without updating the model; outputs may not translate into actionable engineering work}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Define criteria that trigger threat modeling (internet-facing, sensitive data, auth changes, new integrations).
  \item \cb Facilitate a threat modeling workshop using a repeatable method (DFD + STRIDE or ATTACK-based).
  \item \cb Capture mitigations as actionable engineering tasks with owners and due dates.
  \item \cb Add security requirements to the architecture decision record for the feature.
  \item \cb Track follow-through during implementation and validate mitigations in pre-release review.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: A high-risk feature receives a threat model before implementation
  Given a feature meets threat modeling trigger criteria
  When the AppSec engineer schedules and runs the threat modeling session
  Then a documented model and prioritized threat list is produced
  And mitigations are captured as tracked work items with owners
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-TM-002}{Create reusable security requirements for common architectural patterns}{Secure Design and Threat Modeling}
{Reduce security review time and improve consistency by providing pre-approved controls for standard patterns (REST APIs, event-driven services, web apps, mobile backends)}
{Should}{3}
{AppSec engineer}
{Architecture patterns catalog; platform standards (identity, secrets, logging); documentation platform}
{Patterns can become outdated; teams may deviate without notifying AppSec}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Identify the most common architecture patterns in the portfolio and document their trust boundaries.
  \item \cb Define required controls for each pattern (authn/authz, rate limiting, input validation, TLS, secrets, logging).
  \item \cb Provide implementation examples and links to approved libraries and services.
  \item \cb Publish requirements as checklists used in design and release reviews.
  \item \cb Review and update the catalog quarterly based on incidents and new threats.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: Teams can self-serve security requirements for a known pattern
  Given a team is building a service that matches a documented pattern
  When the team consults the pattern requirements
  Then the required security controls are clear and actionable
  And the controls can be verified during review without bespoke analysis
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-SAST-001}{Standardize SAST execution in CI for all supported languages}{SAST Operations}
{Detect code-level vulnerabilities early and consistently across repositories by running SAST on pull requests and default branches with reliable uploads and developer-friendly feedback}
{Must}{5}
{AppSec engineer}
{CI platform support; repo admin access; SAST tooling (for example CodeQL); language build instructions}
{Build failures can block adoption; misconfigured queries increase false positives; runtime/cost overhead in CI}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Inventory repositories and identify languages and build systems.
  \item \cb Create a standard CI workflow that runs SAST on pull requests and on a scheduled cadence.
  \item \cb Ensure results are uploaded successfully and surfaced in pull request checks.
  \item \cb Document the supported configurations and common troubleshooting steps.
  \item \cb Pilot with representative repositories and iterate before scaling.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: SAST runs on pull requests and reports results
  Given a repository is onboarded to the standard SAST workflow
  When a pull request is opened
  Then the SAST job runs successfully
  And findings are reported back to the pull request in a consistent format

Scenario: SAST runs on a schedule to catch drift
  Given the default branch changes over time
  When the scheduled SAST job runs
  Then the latest default branch is scanned
  And new findings are recorded and routed to owners
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-SAST-002}{Implement risk-based merge gating for critical SAST findings}{SAST Enforcement}
{Prevent introduction of high-impact vulnerabilities by blocking merges when new Critical findings are introduced and requiring formal waivers for exceptions}
{Must}{5}
{AppSec engineer}
{Branch protection or merge rules; stable SAST checks; defined waiver process}
{False positives can stall development; legacy code may require phased rollout; gating without support increases friction}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Define which severities and categories are gate-breaking (for example Critical only for phase 1).
  \item \cb Configure protected branches to require the SAST check and enforce gate rules.
  \item \cb Implement a waiver mechanism tied to an approval record and an expiry date.
  \item \cb Run a controlled test to validate gating behavior and waiver paths.
  \item \cb Publish developer guidance for triage, remediation, and waiver requests.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: Pull request is blocked when it introduces a new critical SAST finding
  Given the protected branch requires the SAST status check
  When a pull request introduces a new critical finding in changed code
  Then the SAST check fails
  And the pull request cannot be merged until the finding is fixed or waived

Scenario: Approved waiver allows merge with traceability
  Given a critical finding cannot be remediated immediately
  When an approved waiver with an expiry date is attached to the pull request
  Then the merge gate is satisfied for that finding
  And the waiver record is linked for audit and later review
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-SAST-003}{Reduce SAST noise with baselining and incremental scanning}{SAST Triage and Noise Reduction}
{Improve signal-to-noise ratio by focusing engineers on findings introduced or modified in current changes while tracking legacy backlog separately}
{Should}{3}
{AppSec engineer}
{Tooling support for baselines and diff-aware analysis; alert export access}
{Over-aggressive suppression can hide real risk; baseline drift if not maintained}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Create an initial baseline snapshot of existing SAST findings per repository.
  \item \cb Configure reporting to emphasize new findings in changed code paths.
  \item \cb Define triage outcomes (true positive, false positive, won't fix, accepted risk) and tagging conventions.
  \item \cb Establish a legacy backlog plan with targets for burn-down on critical assets.
  \item \cb Review suppression rules monthly to ensure they remain valid.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: Engineers see new findings separately from legacy backlog
  Given a repository has an established SAST baseline
  When a pull request is analyzed
  Then findings introduced by the pull request are highlighted
  And legacy findings are still tracked but do not block by default
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-SECRETS-001}{Enable organization-wide secret scanning with push protection}{Secrets Management and Detection}
{Prevent credential leakage by detecting and blocking secrets before they are committed, reducing incident response and key rotation cost}
{Must}{5}
{AppSec engineer}
{Git platform secret scanning capability; approved remediation playbook; owner contact data}
{False positives can frustrate developers; unmanaged keys in legacy repos; inconsistent key rotation ownership}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Enable secret scanning across target repositories and define rollout phases.
  \item \cb Turn on push protection for high-risk secret types and validate developer UX.
  \item \cb Define notification paths and on-call procedures for confirmed secrets.
  \item \cb Publish a remediation playbook for triage, rotation, and post-incident review.
  \item \cb Create dashboards for secret types, exposure window, and time-to-rotate.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: Push protection blocks a secret from being committed
  Given push protection is enabled for a supported secret type
  When a developer attempts to push a commit containing a secret
  Then the push is blocked with guidance for remediation
  And a security event is recorded for auditing

Scenario: Confirmed secret triggers rotation workflow
  Given a secret is detected and confirmed as valid
  When the AppSec engineer initiates the rotation process
  Then the secret is revoked or rotated
  And the incident record documents the exposure window and root cause
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-SECRETS-002}{Create and maintain custom secret scanning patterns for internal tokens}{Secrets Management and Detection}
{Detect organization-specific credentials and tokens that generic detectors miss, closing gaps in coverage for internal systems}
{Should}{3}
{AppSec engineer}
{Token format definitions from service owners; testing repositories; allowlist strategy}
{Poorly designed patterns increase false positives; patterns may leak token format details if shared broadly}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Collect internal token formats from service owners and define detection requirements.
  \item \cb Implement custom patterns with validation checks to reduce false positives.
  \item \cb Test patterns on representative repositories and tune based on results.
  \item \cb Define allowlists for known safe test strings and documentation examples.
  \item \cb Create an owner and review cadence for pattern maintenance.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: Custom patterns detect internal tokens in commits
  Given custom secret patterns are enabled for internal token formats
  When a commit contains an internal token string
  Then secret scanning generates an alert with the custom detector name
  And the alert follows standard routing and remediation workflow
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-SCA-001}{Enable dependency vulnerability alerts and ownership routing}{Software Composition Analysis}
{Reduce risk from known vulnerable dependencies by continuously detecting advisories, routing alerts to owners, and tracking remediation progress}
{Must}{5}
{AppSec engineer}
{Dependency scanning support; repository ownership mapping; package manager coverage}
{Alert volume can be high; transitive dependency fixes may be non-trivial; ownership gaps in legacy repos}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Enable dependency vulnerability alerts across repositories and validate coverage by ecosystem.
  \item \cb Define ownership mapping (CODEOWNERS, repo metadata, service catalog) for routing.
  \item \cb Configure alert notifications to route to the correct team or ticket queue.
  \item \cb Create triage guidance: patch, upgrade, replace, or accept risk with justification.
  \item \cb Track SLA compliance and recurrence of similar vulnerable packages.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: New dependency advisory is routed to the owning team
  Given a repository has defined ownership information
  When a new advisory affects a dependency in that repository
  Then an alert is generated and assigned to the owning team
  And a remediation ticket is created with severity and due date
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-SCA-002}{Automate dependency updates with scheduled pull requests}{Software Composition Analysis}
{Lower mean time to patch by continuously proposing safe upgrades via automated pull requests, with guardrails for testing and rollout}
{Should}{3}
{AppSec engineer}
{Automated update tooling; reliable test suites; branch protection configuration}
{Update PR noise; breaking changes; insufficient test coverage}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Enable automated dependency update PRs with sensible schedules and grouping.
  \item \cb Configure ignore rules for known-breaking major versions and define review requirements.
  \item \cb Ensure CI tests run on update PRs and capture failure reasons.
  \item \cb Define escalation for critical advisories to fast-track patching.
  \item \cb Measure adoption: time-to-merge, failure rates, and rollback events.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: Automated update PR is created and tested
  Given automated updates are enabled for a repository
  When the scheduled update window occurs
  Then an update pull request is opened with a clear changelog
  And CI tests run automatically on the pull request
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-IAC-001}{Scan infrastructure-as-code and Kubernetes manifests in CI}{Infrastructure and Cloud Security Scanning}
{Prevent misconfigurations from reaching production by detecting insecure IaC patterns (public exposure, overly permissive IAM, weak encryption settings) before merge}
{Must}{5}
{AppSec engineer}
{IaC scanning tooling; CI integration; baseline of allowed configurations; cloud platform standards}
{False positives can block delivery; rule tuning required; coverage gaps for custom modules}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Select and configure IaC scanners for Terraform, Kubernetes YAML, and Helm where applicable.
  \item \cb Define policy rules aligned to organizational cloud standards and security controls.
  \item \cb Integrate scanning into pull requests and provide clear remediation guidance.
  \item \cb Establish a baseline for legacy findings and focus gating on new critical misconfigurations.
  \item \cb Create an exception workflow for approved deviations with compensating controls.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: Pull request fails when it introduces a critical IaC misconfiguration
  Given IaC scanning runs on pull requests
  When a change introduces a critical misconfiguration
  Then the scan check fails with a clear finding and location
  And the pull request cannot be merged until fixed or waived
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-CONTAINER-001}{Implement container image scanning and base image governance}{Infrastructure and Cloud Security Scanning}
{Reduce runtime exposure by detecting vulnerable packages in container images and standardizing on approved, maintained base images}
{Should}{5}
{AppSec engineer}
{Container registry integration; image scanning tooling; approved base images; build pipeline access}
{Large images increase scan time; frequent CVEs create churn; base image change management required}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Enable container image scanning on build and on registry push, and validate alert routing.
  \item \cb Create a catalog of approved base images with patch cadence and ownership.
  \item \cb Define policy for disallowed packages and minimum supported OS versions.
  \item \cb Add CI checks to enforce use of approved base images for new services.
  \item \cb Publish remediation guidance for rebuilding and redeploying patched images.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: New image build is flagged for critical vulnerabilities
  Given an image is built and pushed to the registry
  When the image contains a critical vulnerability
  Then the scan produces an alert and routes it to the image owner
  And the release process blocks or warns according to policy
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-DAST-001}{Establish DAST baseline scanning for internet-facing applications}{DAST and Runtime Testing}
{Detect common web application weaknesses in deployed environments and validate that critical vulnerabilities are not exposed externally}
{Should}{5}
{AppSec engineer}
{Test environments and credentials; DAST tooling; application inventory and URLs}
{Scan impact on performance; auth flows may be complex; false positives require verification}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Identify internet-facing applications and define safe scanning windows.
  \item \cb Configure authenticated scanning where needed and validate coverage.
  \item \cb Define severity thresholds and how findings are verified and tracked.
  \item \cb Integrate DAST results into the vulnerability management workflow.
  \item \cb Create a recurring cadence and exception rules for sensitive systems.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: DAST scan runs successfully against a target application
  Given a target application has an approved scanning window and credentials
  When the DAST job runs
  Then the scan completes without exceeding agreed performance limits
  And findings are recorded with evidence and reproduction steps
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-VULN-001}{Integrate security findings into the vulnerability management ticketing system}{Vulnerability Management}
{Ensure findings are actionable and trackable by creating standardized tickets with ownership, severity, due dates, and audit-ready traceability}
{Must}{5}
{AppSec engineer}
{Ticketing system APIs; ownership mapping; standardized fields and templates}
{Duplicate tickets if deduplication is weak; ownership data may be stale; API rate limits}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Define a common vulnerability ticket schema (tool, rule, location, severity, due date, remediation guidance).
  \item \cb Implement ingestion from scanners (SAST, SCA, secrets, IaC, container) with deduplication keys.
  \item \cb Map repositories and services to owners and escalation paths.
  \item \cb Create dashboards for open items by team, SLA status, and aging.
  \item \cb Pilot with one tool stream, then scale to all sources.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: A new security finding creates a single deduplicated ticket
  Given a scanner reports a new finding for a repository
  When the ingestion job processes the finding
  Then exactly one ticket is created or updated for that finding
  And the ticket includes owner, severity, and due date
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-VULN-002}{Implement automated SLA reminders and escalation for overdue vulnerabilities}{Vulnerability Management}
{Drive timely remediation by notifying owners of approaching deadlines and escalating overdue items to engineering leadership with clear context}
{Should}{3}
{AppSec engineer}
{Ticketing notification capabilities; team escalation contacts; SLA matrix}
{Notification fatigue if too noisy; escalation without context can damage trust}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Configure reminders for due-soon and overdue items by severity tier.
  \item \cb Include context in reminders (evidence, fix guidance, owner, due date, risk).
  \item \cb Implement escalation rules (team lead, manager, leadership) after defined thresholds.
  \item \cb Provide a mechanism for owners to request help or a risk acceptance review.
  \item \cb Monitor reminder effectiveness (closure rates, time-to-close) and tune frequency.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: Owner is reminded before an SLA breach
  Given a vulnerability ticket is within the reminder window before its due date
  When the reminder job runs
  Then the remediation owner receives a notification with actionable guidance
  And the ticket is updated with the reminder timestamp

Scenario: Overdue critical vulnerability is escalated
  Given a critical vulnerability ticket is overdue
  When the escalation threshold is met
  Then an escalation notification is sent to the owner and leadership chain
  And the escalation is recorded on the ticket for auditability
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-EXC-001}{Create a time-bound risk acceptance and exception workflow}{Risk Acceptance and Exceptions}
{Enable controlled exceptions without losing visibility by requiring business justification, compensating controls, and an explicit expiry and revalidation process}
{Must}{3}
{AppSec engineer}
{Risk owner approval process; ticketing workflow support; audit requirements}
{Exceptions can become permanent without expiry; inconsistent approvals; lack of compensating controls}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Define criteria for when risk acceptance is allowed and required approvers.
  \item \cb Create an exception request form capturing justification, controls, scope, and expiry date.
  \item \cb Link exceptions to specific findings or controls and ensure they are discoverable.
  \item \cb Implement reminders for upcoming expirations and forced revalidation.
  \item \cb Report on active exceptions by age, scope, and business unit.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: Exception request requires expiry and approval
  Given an engineer requests an exception for a security finding
  When the request is submitted
  Then it must include a business justification, compensating controls, and an expiry date
  And it is not effective until the required approvers approve it

Scenario: Expired exceptions are surfaced for revalidation
  Given an approved exception has reached its expiry date
  When the exception review job runs
  Then the exception is flagged as expired
  And owners are notified to remediate or re-approve with updated justification
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-SBOM-001}{Generate and publish an SBOM for each release artifact}{Supply Chain Security}
{Improve transparency and response speed by producing a standardized SBOM per release so affected components can be identified quickly during vulnerability disclosures}
{Should}{5}
{AppSec engineer}
{Build pipeline updates; SBOM tooling; artifact repository support; release process ownership}
{Inconsistent formats reduce usefulness; incomplete dependency capture for some ecosystems; storage and access controls}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Select an SBOM format and tooling and define minimum required fields.
  \item \cb Integrate SBOM generation into build pipelines for release artifacts.
  \item \cb Store SBOMs alongside artifacts with appropriate access controls and retention.
  \item \cb Validate SBOM completeness by comparing to build manifests and lockfiles.
  \item \cb Document how to query SBOMs during incident response and disclosures.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: Release artifacts include a corresponding SBOM
  Given a build produces a release artifact
  When the release pipeline completes
  Then an SBOM is generated for the artifact
  And the SBOM is stored and linked to the release record
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-SUPPLY-001}{Implement artifact signing and provenance for release builds}{Supply Chain Security}
{Reduce supply chain tampering risk by ensuring release artifacts are signed and have verifiable provenance from CI to production}
{Should}{5}
{AppSec engineer}
{CI signing keys or keyless signing service; artifact repository support; deployment verification hooks}
{Key management complexity; tooling integration effort; legacy pipelines may not support provenance}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Define the signing standard and verification points in the pipeline.
  \item \cb Implement signing for build artifacts and container images.
  \item \cb Produce provenance metadata describing the build inputs and environment.
  \item \cb Verify signatures during deployment and fail deployments on missing or invalid signatures.
  \item \cb Create runbooks for key rotation, incident response, and audit review.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: Deployment verifies artifact signature before release
  Given a release artifact is signed during CI
  When the deployment pipeline runs
  Then the pipeline verifies the signature and provenance
  And deployment is blocked if verification fails
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-ACCESS-001}{Harden repository access and branch protections for critical services}{Secure SDLC Controls}
{Reduce risk of unauthorized changes and compromised accounts by enforcing least privilege, mandatory reviews, and strong branch protections}
{Must}{3}
{AppSec engineer}
{Git hosting admin support; identity provider controls; CODEOWNERS and rulesets}
{Over-restrictive rules slow emergency fixes; inconsistent ownership definitions}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Define repository criticality tiers and apply stronger controls to tier-1 repos.
  \item \cb Enforce mandatory reviews, signed commits where feasible, and restricted force-push.
  \item \cb Require status checks for security scans and tests on protected branches.
  \item \cb Implement periodic access reviews for privileged repo roles.
  \item \cb Create an emergency change process with audit logging and post-hoc review.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: Protected branches prevent direct pushes
  Given a repository is classified as tier-1
  When a user attempts to push directly to the protected branch
  Then the push is rejected
  And changes must be introduced via a pull request with required checks
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-TRAIN-001}{Deliver just-in-time secure coding enablement for recurring findings}{Developer Enablement}
{Reduce recurring vulnerabilities by pairing findings with targeted guidance, examples, and office hours that help engineers fix issues correctly and sustainably}
{Should}{3}
{AppSec engineer}
{Developer documentation platform; training content; engineering time for office hours}
{Content becomes stale; lack of participation; guidance not tailored to local frameworks}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Analyze top recurring finding types across SAST, secrets, and SCA streams.
  \item \cb Create short fix guides and code examples for each recurring finding type.
  \item \cb Link fix guides directly from finding descriptions or ticket templates.
  \item \cb Run regular office hours focused on the top two finding types each cycle.
  \item \cb Measure improvement via recurrence rate and time-to-fix metrics.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: Engineers can access fix guidance from a finding
  Given a finding is opened in the tracking system
  When an engineer views the finding details
  Then a link to a relevant fix guide and examples is available
  And the guide includes preferred libraries and common pitfalls
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-METRICS-001}{Publish a unified AppSec metrics dashboard for leadership and teams}{Metrics and Reporting}
{Provide actionable visibility into risk, remediation performance, and control health so leaders can allocate capacity and teams can self-correct}
{Must}{5}
{AppSec engineer}
{Data sources from scanners and ticketing; BI or dashboard platform; agreed KPI definitions}
{Metrics can be gamed; inconsistent data quality; over-emphasis on counts instead of risk}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Define core KPIs: open critical/high by asset tier, time-to-triage, time-to-fix, SLA compliance, secrets time-to-rotate, scan coverage.
  \item \cb Implement data ingestion and normalization across tools into a single dataset.
  \item \cb Build dashboard views for leadership, engineering managers, and teams.
  \item \cb Add trend lines and highlight top outliers needing help.
  \item \cb Publish a weekly cadence and a short narrative summary of changes.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: Dashboard shows current risk posture by team and severity
  Given the dashboard ingests findings and ticket status data
  When a user selects a team or repository
  Then the dashboard displays open items by severity and SLA status
  And trends are available for at least the previous four weeks
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-IR-001}{Develop and exercise an incident response playbook for source code compromise}{Incident Response and Readiness}
{Reduce impact of credential compromise or malicious code changes by having a practiced response plan for repositories, CI, and release artifacts}
{Should}{5}
{AppSec engineer}
{Incident response team alignment; access to audit logs; runbook ownership; tabletop exercise participation}
{Playbook not maintained; unclear authority during incidents; incomplete logging reduces investigation capability}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Define incident triggers and severity for repo compromise scenarios.
  \item \cb Document containment steps: revoke tokens, lock down repos, rotate credentials, suspend CI runners, invalidate artifacts.
  \item \cb Define investigation steps using audit logs, commit history, and CI logs.
  \item \cb Define recovery steps: rebuild from trusted commit, re-sign artifacts, redeploy, and monitor.
  \item \cb Run a tabletop exercise and incorporate lessons learned into the playbook.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: Source code compromise triggers containment within defined time
  Given an alert indicates unauthorized changes in a critical repository
  When the incident is declared
  Then containment actions are executed according to the playbook
  And all actions are logged in the incident record with timestamps
\end{lstlisting}

\clearpage

\StoryCard{APPSEC-OSS-001}{Enforce open source usage and license compliance controls}{Supply Chain Security}
{Reduce legal and operational risk by ensuring open source components meet license policies and prohibited licenses are flagged before release}
{Could}{5}
{AppSec engineer}
{Legal input on license policy; SCA tooling with license detection; release process integration}
{License data may be incomplete; policy disputes can block releases; exceptions must be traceable}

\begin{TasksBox}[Implementation Tasks]
  \item \cb Define allowed, restricted, and prohibited licenses with legal and security stakeholders.
  \item \cb Enable license detection and reporting in the dependency scanning stream.
  \item \cb Add a pre-release check that flags prohibited licenses and requires approval for exceptions.
  \item \cb Create a workflow for replacing or re-licensing components when blocked.
  \item \cb Publish reporting for license posture and exceptions.
\end{TasksBox}

\textbf{Acceptance Criteria (Gherkin)}
\begin{lstlisting}[language=Gherkin]
Scenario: Prohibited license is detected before release
  Given a repository includes a dependency with a prohibited license
  When the pre-release compliance check runs
  Then the release is blocked or flagged according to policy
  And the finding includes the dependency path and remediation options
\end{lstlisting}

\clearpage

\end{document}
